"""ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­ text_scale çš„æ¼”å˜

è¿™ä¸ªè„šæœ¬å¯ä»¥ï¼š
1. ä»è®­ç»ƒ checkpoints ä¸­æå– text_scale å€¼
2. ç»˜åˆ¶ text_scale éšè®­ç»ƒè¿›ç¨‹çš„å˜åŒ–
3. åˆ†æ text_scale æ˜¯å¦æ”¶æ•›

ä½¿ç”¨æ–¹æ³•:
python monitor_text_scale.py \
    --checkpoint_dir ./outputs/improved_fusion \
    --output_plot text_scale_evolution.png
"""

import argparse
import os
import glob
import torch
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path


def extract_text_scale_from_checkpoint(checkpoint_path):
    """ä» checkpoint ä¸­æå– text_scale å€¼"""
    try:
        ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        model_state = ckpt['model']

        text_scales = {}
        for key, value in model_state.items():
            if 'text_scale' in key and 'middle_fusion' in key:
                # æå–å±‚å·ï¼Œä¾‹å¦‚ 'middle_fusion_modules.layer_2.text_scale' -> 'layer_2'
                layer_name = key.split('.')[1]  # 'layer_2'
                text_scales[layer_name] = value.item()

        # è·å– epoch ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        epoch = ckpt.get('epoch', None)

        return text_scales, epoch
    except Exception as e:
        print(f"âš ï¸  æ— æ³•åŠ è½½ {checkpoint_path}: {e}")
        return None, None


def find_checkpoints(checkpoint_dir):
    """æŸ¥æ‰¾æ‰€æœ‰ checkpoint æ–‡ä»¶"""
    # æŸ¥æ‰¾å¸¸è§çš„ checkpoint å‘½åæ¨¡å¼
    patterns = [
        'checkpoint_*.pt',
        'model_epoch_*.pt',
        'best_model.pt',
        'best_test_model.pt'
    ]

    checkpoint_files = []
    for pattern in patterns:
        checkpoint_files.extend(glob.glob(os.path.join(checkpoint_dir, pattern)))

    return sorted(checkpoint_files)


def main():
    parser = argparse.ArgumentParser(description="ç›‘æ§ text_scale æ¼”å˜")
    parser.add_argument('--checkpoint_dir', required=True, help='checkpoint ç›®å½•')
    parser.add_argument('--output_plot', default='text_scale_evolution.png', help='è¾“å‡ºå›¾è¡¨è·¯å¾„')
    parser.add_argument('--checkpoint_pattern', default=None, help='checkpoint æ–‡ä»¶æ¨¡å¼ï¼ˆå¯é€‰ï¼‰')
    args = parser.parse_args()

    print("=" * 80)
    print("ğŸ“Š ç›‘æ§ text_scale æ¼”å˜")
    print("=" * 80)

    # æŸ¥æ‰¾ checkpoints
    if args.checkpoint_pattern:
        checkpoint_files = glob.glob(os.path.join(args.checkpoint_dir, args.checkpoint_pattern))
        checkpoint_files = sorted(checkpoint_files)
    else:
        checkpoint_files = find_checkpoints(args.checkpoint_dir)

    print(f"\nğŸ“‚ æ‰¾åˆ° {len(checkpoint_files)} ä¸ª checkpoints")

    if len(checkpoint_files) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½• checkpoint æ–‡ä»¶")
        print(f"   è¯·æ£€æŸ¥ç›®å½•: {args.checkpoint_dir}")
        return

    # æå–æ•°æ®
    all_data = []
    layer_names = set()

    for i, ckpt_path in enumerate(checkpoint_files):
        text_scales, epoch = extract_text_scale_from_checkpoint(ckpt_path)

        if text_scales:
            layer_names.update(text_scales.keys())
            all_data.append({
                'checkpoint': os.path.basename(ckpt_path),
                'index': i,
                'epoch': epoch if epoch is not None else i,
                'text_scales': text_scales
            })

            # æ‰“å°è¿›åº¦
            if (i + 1) % 10 == 0:
                print(f"   å¤„ç†è¿›åº¦: {i + 1}/{len(checkpoint_files)}")

    if len(all_data) == 0:
        print("\nâŒ æ‰€æœ‰ checkpoints éƒ½æ— æ³•æå– text_scale")
        return

    print(f"\nâœ… æˆåŠŸæå– {len(all_data)} ä¸ª checkpoints çš„æ•°æ®")
    print(f"   æ‰¾åˆ°çš„å±‚: {sorted(layer_names)}")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“ˆ text_scale ç»Ÿè®¡")
    print("=" * 80)

    for layer_name in sorted(layer_names):
        scales = [d['text_scales'].get(layer_name, None) for d in all_data]
        scales = [s for s in scales if s is not None]

        if scales:
            print(f"\n{layer_name}:")
            print(f"   åˆå§‹å€¼: {scales[0]:.4f}")
            print(f"   æœ€ç»ˆå€¼: {scales[-1]:.4f}")
            print(f"   å˜åŒ–: {scales[-1] - scales[0]:+.4f} ({(scales[-1] - scales[0]) / scales[0] * 100:+.2f}%)")
            print(f"   æœ€å°å€¼: {min(scales):.4f}")
            print(f"   æœ€å¤§å€¼: {max(scales):.4f}")
            print(f"   å¹³å‡å€¼: {np.mean(scales):.4f}")
            print(f"   æ ‡å‡†å·®: {np.std(scales):.4f}")

    # ç»˜åˆ¶å›¾è¡¨
    print(f"\nğŸ“Š ç”Ÿæˆå›¾è¡¨: {args.output_plot}")

    fig, axes = plt.subplots(2, 1, figsize=(12, 10))

    # å›¾ 1: text_scale éšè®­ç»ƒè¿›ç¨‹çš„å˜åŒ–
    ax1 = axes[0]
    for layer_name in sorted(layer_names):
        epochs = [d['epoch'] for d in all_data if layer_name in d['text_scales']]
        scales = [d['text_scales'][layer_name] for d in all_data if layer_name in d['text_scales']]

        ax1.plot(epochs, scales, marker='o', label=layer_name, linewidth=2, markersize=4)

    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('text_scale Value', fontsize=12)
    ax1.set_title('Evolution of Learnable Text Scaling Factor', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=12.0, color='red', linestyle='--', alpha=0.5, label='Initial Value (12.0)')

    # å›¾ 2: text_scale çš„å˜åŒ–ç‡
    ax2 = axes[1]
    for layer_name in sorted(layer_names):
        scales = [d['text_scales'][layer_name] for d in all_data if layer_name in d['text_scales']]

        if len(scales) > 1:
            # è®¡ç®—å˜åŒ–ç‡ï¼ˆç›¸é‚» epoch çš„å·®å€¼ï¼‰
            change_rates = np.diff(scales)
            epochs = [d['epoch'] for d in all_data if layer_name in d['text_scales']][1:]

            ax2.plot(epochs, change_rates, marker='o', label=layer_name, linewidth=2, markersize=4)

    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Change Rate (Î”text_scale)', fontsize=12)
    ax2.set_title('Rate of Change in Text Scaling Factor', fontsize=14, fontweight='bold')
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)

    plt.tight_layout()
    plt.savefig(args.output_plot, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜")

    # åˆ†ææ”¶æ•›æ€§
    print("\n" + "=" * 80)
    print("ğŸ” æ”¶æ•›æ€§åˆ†æ")
    print("=" * 80)

    for layer_name in sorted(layer_names):
        scales = [d['text_scales'][layer_name] for d in all_data if layer_name in d['text_scales']]

        if len(scales) > 10:
            # åˆ†ææœ€å 10 ä¸ª epoch çš„å˜åŒ–
            recent_scales = scales[-10:]
            recent_std = np.std(recent_scales)
            recent_mean = np.mean(recent_scales)

            print(f"\n{layer_name} (æœ€å 10 ä¸ª epochs):")
            print(f"   å¹³å‡å€¼: {recent_mean:.4f}")
            print(f"   æ ‡å‡†å·®: {recent_std:.4f}")
            print(f"   å˜åŒ–èŒƒå›´: [{min(recent_scales):.4f}, {max(recent_scales):.4f}]")

            # åˆ¤æ–­æ”¶æ•›
            if recent_std < 0.5:
                print(f"   âœ… å·²æ”¶æ•›ï¼ˆæ ‡å‡†å·® < 0.5ï¼‰")
            elif recent_std < 1.0:
                print(f"   âš ï¸  æ¥è¿‘æ”¶æ•›ï¼ˆæ ‡å‡†å·® < 1.0ï¼‰")
            else:
                print(f"   âŒ ä»åœ¨å˜åŒ–ï¼ˆæ ‡å‡†å·® > 1.0ï¼‰ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒ")

    # æä¾›å»ºè®®
    print("\n" + "=" * 80)
    print("ğŸ’¡ å»ºè®®")
    print("=" * 80)

    for layer_name in sorted(layer_names):
        scales = [d['text_scales'][layer_name] for d in all_data if layer_name in d['text_scales']]
        final_scale = scales[-1]

        print(f"\n{layer_name}:")
        if final_scale > 20.0:
            print(f"   âš ï¸  æœ€ç»ˆç¼©æ”¾å€¼ {final_scale:.2f} è¾ƒé«˜")
            print(f"      â€¢ text_transform è¾“å‡ºå¯èƒ½ä»ç„¶è¾ƒå¼±")
            print(f"      â€¢ å»ºè®®å¢åŠ  middle_fusion_initial_scale åˆ° {final_scale * 1.2:.1f}")
        elif final_scale < 5.0:
            print(f"   âš ï¸  æœ€ç»ˆç¼©æ”¾å€¼ {final_scale:.2f} è¾ƒä½")
            print(f"      â€¢ text_transform è¾“å‡ºå¯èƒ½è¿‡å¼º")
            print(f"      â€¢ å»ºè®®æ£€æŸ¥ text_transform åˆå§‹åŒ–")
        else:
            print(f"   âœ… æœ€ç»ˆç¼©æ”¾å€¼ {final_scale:.2f} åœ¨åˆç†èŒƒå›´å†…")

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
