"""
ä¸ºæ‰€æœ‰JARVISæ•°æ®ç”Ÿæˆä¼ªLOBSTERç‰¹å¾

ä½¿ç”¨è®­ç»ƒå¥½çš„LOBSTERé¢„æµ‹å™¨ä¸ºæ‰€æœ‰JARVISæ ·æœ¬ç”ŸæˆICOHPå’ŒICOBIç‰¹å¾

ä½¿ç”¨æ–¹æ³•ï¼š
    python generate_pseudo_lobster_features.py \
        --model_path models/lobster_predictor/best_model.pt \
        --dataset dft_3d \
        --output_file data/pseudo_lobster_features.pkl

ä½œè€…ï¼šClaude
æ—¥æœŸï¼š2025-12-10
"""

import os
import sys
import argparse
import pickle
from pathlib import Path

import torch
import numpy as np
from tqdm import tqdm
import dgl

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

from models.lobster_predictor import LOBSTERPredictorEnsemble
from jarvis.db.figshare import data as jarvis_data
from data import load_jarvis_data_smart
from graphs import Graph


def load_model(checkpoint_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„LOBSTERé¢„æµ‹å™¨

    Args:
        checkpoint_path: checkpointè·¯å¾„
        device: è®¾å¤‡

    Returns:
        model: åŠ è½½çš„æ¨¡å‹
        args: è®­ç»ƒæ—¶çš„å‚æ•°
    """
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {checkpoint_path}")

    checkpoint = torch.load(checkpoint_path, map_location=device)

    # è·å–æ¨¡å‹å‚æ•°
    args = checkpoint.get('args', None)

    # åˆ›å»ºæ¨¡å‹
    model = LOBSTERPredictorEnsemble(
        atom_feature_dim=92,
        edge_hidden_dim=getattr(args, 'edge_hidden_dim', 128),
        graph_hidden_dim=getattr(args, 'graph_hidden_dim', 256),
        num_layers=getattr(args, 'num_layers', 4),
        dropout=getattr(args, 'dropout', 0.1),
        shared_encoder=getattr(args, 'shared_encoder', True)
    )

    # åŠ è½½æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()

    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    # æ‰“å°éªŒè¯æŒ‡æ ‡
    if 'val_metrics' in checkpoint:
        val_metrics = checkpoint['val_metrics']
        print(f"\næ¨¡å‹æ€§èƒ½:")
        print(f"  ICOHP MAE: {val_metrics['mae']['icohp']:.4f}")
        print(f"  ICOBI MAE: {val_metrics['mae']['icobi']:.4f}")
        print(f"  ICOHPç›¸å…³ç³»æ•°: {val_metrics['correlation']['icohp']:.4f}")
        print(f"  ICOBIç›¸å…³ç³»æ•°: {val_metrics['correlation']['icobi']:.4f}")

    return model, args


def generate_features_for_sample(model, g, device, return_uncertainty=True):
    """ä¸ºå•ä¸ªæ ·æœ¬ç”ŸæˆLOBSTERç‰¹å¾

    Args:
        model: LOBSTERé¢„æµ‹å™¨
        g: DGLå›¾
        device: è®¾å¤‡
        return_uncertainty: æ˜¯å¦è¿”å›ä¸ç¡®å®šæ€§

    Returns:
        features: {
            'icohp_mean': [num_edges],
            'icohp_std': [num_edges] (å¯é€‰),
            'icobi': [num_edges],
            'icohp_global_mean': float,
            'icohp_global_min': float,
            'num_bonds': int
        }
    """
    g = g.to(device)

    with torch.no_grad():
        if return_uncertainty:
            icohp_pred, icohp_std, icobi_pred = model(
                g, return_uncertainty=True
            )
        else:
            icohp_pred, icobi_pred = model(g, return_uncertainty=False)
            icohp_std = None

    # è½¬æ¢ä¸ºnumpy
    icohp_mean = icohp_pred.cpu().numpy().flatten()
    icobi = icobi_pred.cpu().numpy().flatten()

    # è®¡ç®—å…¨å±€ç»Ÿè®¡ç‰¹å¾
    icohp_global_mean = float(icohp_mean.mean())
    icohp_global_min = float(icohp_mean.min())  # æœ€å¼ºé”®
    icohp_global_max = float(icohp_mean.max())
    icohp_global_std = float(icohp_mean.std())
    num_bonds = len(icohp_mean)

    features = {
        # è¾¹çº§ç‰¹å¾ï¼ˆç”¨äºGNNï¼‰
        'icohp_mean': icohp_mean,
        'icobi': icobi,

        # å…¨å±€ç‰¹å¾ï¼ˆç”¨äºç‰¹å¾å·¥ç¨‹æˆ–MLPï¼‰
        'icohp_global_mean': icohp_global_mean,
        'icohp_global_min': icohp_global_min,
        'icohp_global_max': icohp_global_max,
        'icohp_global_std': icohp_global_std,
        'num_bonds': num_bonds,
        'icobi_mean': float(icobi.mean()),
        'icobi_max': float(icobi.max()),
    }

    if icohp_std is not None:
        icohp_uncertainty = icohp_std.cpu().numpy().flatten()
        features['icohp_std'] = icohp_uncertainty
        features['icohp_uncertainty_mean'] = float(icohp_uncertainty.mean())

    return features


def generate_features_batch(model, graphs, device, batch_size=32,
                            return_uncertainty=True):
    """æ‰¹é‡ç”ŸæˆLOBSTERç‰¹å¾

    Args:
        model: LOBSTERé¢„æµ‹å™¨
        graphs: DGLå›¾åˆ—è¡¨
        device: è®¾å¤‡
        batch_size: æ‰¹æ¬¡å¤§å°
        return_uncertainty: æ˜¯å¦è¿”å›ä¸ç¡®å®šæ€§

    Returns:
        features_list: ç‰¹å¾åˆ—è¡¨
    """
    features_list = []

    # åˆ†æ‰¹å¤„ç†
    num_batches = (len(graphs) + batch_size - 1) // batch_size

    for i in tqdm(range(num_batches), desc="ç”Ÿæˆç‰¹å¾"):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, len(graphs))

        batch_graphs = graphs[start_idx:end_idx]

        # æ‰¹æ¬¡å›¾
        batched_g = dgl.batch(batch_graphs)

        # ç”Ÿæˆç‰¹å¾
        with torch.no_grad():
            if return_uncertainty:
                icohp_pred, icohp_std, icobi_pred = model(
                    batched_g.to(device), return_uncertainty=True
                )
            else:
                icohp_pred, icobi_pred = model(
                    batched_g.to(device), return_uncertainty=False
                )
                icohp_std = None

        # è½¬æ¢ä¸ºCPU
        icohp_pred = icohp_pred.cpu().numpy()
        icobi_pred = icobi_pred.cpu().numpy()

        if icohp_std is not None:
            icohp_std = icohp_std.cpu().numpy()

        # åˆ†è§£æ‰¹æ¬¡ç»“æœ
        edge_offset = 0
        for j, g in enumerate(batch_graphs):
            num_edges = g.num_edges()

            # æå–è¯¥å›¾çš„ç‰¹å¾
            icohp_edges = icohp_pred[edge_offset:edge_offset+num_edges].flatten()
            icobi_edges = icobi_pred[edge_offset:edge_offset+num_edges].flatten()

            features = {
                'icohp_mean': icohp_edges,
                'icobi': icobi_edges,
                'icohp_global_mean': float(icohp_edges.mean()),
                'icohp_global_min': float(icohp_edges.min()),
                'icohp_global_max': float(icohp_edges.max()),
                'icohp_global_std': float(icohp_edges.std()),
                'num_bonds': num_edges,
                'icobi_mean': float(icobi_edges.mean()),
                'icobi_max': float(icobi_edges.max()),
            }

            if icohp_std is not None:
                icohp_unc = icohp_std[edge_offset:edge_offset+num_edges].flatten()
                features['icohp_std'] = icohp_unc
                features['icohp_uncertainty_mean'] = float(icohp_unc.mean())

            features_list.append(features)

            edge_offset += num_edges

    return features_list


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä¸ºJARVISæ•°æ®ç”Ÿæˆä¼ªLOBSTERç‰¹å¾'
    )

    parser.add_argument('--model_path', type=str, required=True,
                       help='è®­ç»ƒå¥½çš„LOBSTERé¢„æµ‹å™¨è·¯å¾„')
    parser.add_argument('--dataset', type=str, default='dft_3d',
                       help='JARVISæ•°æ®é›†åç§°')
    parser.add_argument('--atom_features', type=str, default='cgcnn',
                       help='åŸå­ç‰¹å¾ç±»å‹')
    parser.add_argument('--output_file', type=str,
                       default='data/pseudo_lobster_features.pkl',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_size', type=int, default=32,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--max_samples', type=int, default=None,
                       help='æœ€å¤§æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--return_uncertainty', action='store_true',
                       help='æ˜¯å¦è¿”å›ä¸ç¡®å®šæ€§')

    args = parser.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(args.output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹
    model, train_args = load_model(args.model_path, device)

    # åŠ è½½JARVISæ•°æ®
    print(f"\nğŸ“Š åŠ è½½JARVISæ•°æ®é›†: {args.dataset}")
    jarvis_db = load_jarvis_data_smart(args.dataset)

    # é™åˆ¶æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    if args.max_samples is not None:
        jarvis_db = jarvis_db[:args.max_samples]
        print(f"   é™åˆ¶æ ·æœ¬æ•°: {args.max_samples}")

    print(f"   æ€»æ ·æœ¬æ•°: {len(jarvis_db)}")

    # æ„å»ºå›¾
    print("\nğŸ”¨ æ„å»ºæ™¶ä½“å›¾...")
    graphs = []
    jids = []

    for entry in tqdm(jarvis_db):
        try:
            atoms = entry['atoms']
            jid = entry['jid']

            # æ„å»ºDGLå›¾
            g, _ = Graph.atom_dgl_multigraph(
                atoms,
                cutoff=8.0,
                max_neighbors=12,
                atom_features=args.atom_features,
                compute_line_graph=False
            )

            graphs.append(g)
            jids.append(jid)

        except Exception as e:
            print(f"âš ï¸  è·³è¿‡æ ·æœ¬ {entry.get('jid', 'unknown')}: {e}")
            continue

    print(f"âœ… æˆåŠŸæ„å»º {len(graphs)} ä¸ªå›¾")

    # ç”Ÿæˆç‰¹å¾
    print(f"\nğŸš€ ç”Ÿæˆä¼ªLOBSTERç‰¹å¾...")
    print(f"   æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"   è¿”å›ä¸ç¡®å®šæ€§: {args.return_uncertainty}")

    features_list = generate_features_batch(
        model=model,
        graphs=graphs,
        device=device,
        batch_size=args.batch_size,
        return_uncertainty=args.return_uncertainty
    )

    # æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„
    print("\nğŸ“¦ æ•´ç†æ•°æ®...")
    pseudo_lobster_db = {}

    for jid, features in zip(jids, features_list):
        pseudo_lobster_db[jid] = features

    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {args.output_file}")
    with open(args.output_file, 'wb') as f:
        pickle.dump(pseudo_lobster_db, f)

    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    print("="*60)

    all_icohp = [f['icohp_global_mean'] for f in features_list]
    all_icohp_min = [f['icohp_global_min'] for f in features_list]

    print(f"æ€»æ ·æœ¬æ•°: {len(pseudo_lobster_db)}")
    print(f"\nICOHPç»Ÿè®¡:")
    print(f"  å¹³å‡ICOHPèŒƒå›´: [{np.min(all_icohp):.3f}, {np.max(all_icohp):.3f}]")
    print(f"  æœ€å¼ºé”®ICOHPèŒƒå›´: [{np.min(all_icohp_min):.3f}, {np.max(all_icohp_min):.3f}]")

    if args.return_uncertainty:
        all_unc = [f['icohp_uncertainty_mean'] for f in features_list]
        print(f"\nä¸ç¡®å®šæ€§ç»Ÿè®¡:")
        print(f"  å¹³å‡ä¸ç¡®å®šæ€§: {np.mean(all_unc):.3f}")
        print(f"  ä¸ç¡®å®šæ€§èŒƒå›´: [{np.min(all_unc):.3f}, {np.max(all_unc):.3f}]")

    print("="*60)
    print("âœ… ç‰¹å¾ç”Ÿæˆå®Œæˆï¼")


if __name__ == '__main__':
    main()
