# ğŸš€ ä¸­æœŸèåˆç²¾åº¦æå‡æ”¹è¿›æ–¹æ¡ˆ

## ğŸ“Š å½“å‰ä¸­æœŸèåˆå®ç°åˆ†æ

### ç°æœ‰ç‰¹æ€§
```python
MiddleFusionModule:
  1. æ–‡æœ¬å˜æ¢: Linear(768â†’128â†’64) + ReLU + Dropout
  2. å¯å­¦ä¹ ç¼©æ”¾: text_scale (åˆå§‹å€¼=12.0) âœ…
  3. Gateå½’ä¸€åŒ–: LayerNorm(128) âœ…
  4. é—¨æ§æœºåˆ¶: Sigmoid(Linear(128))
  5. æ®‹å·®è¿æ¥: output = node_feat + gate * text_feat
  6. å±‚å½’ä¸€åŒ–: LayerNorm(64)
```

### å½“å‰é™åˆ¶
1. âŒ **ç®€å•é—¨æ§**: å•ä¸€Sigmoidé—¨æ§ï¼Œè¡¨è¾¾èƒ½åŠ›æœ‰é™
2. âŒ **é™æ€èåˆ**: æ‰€æœ‰èŠ‚ç‚¹ä½¿ç”¨ç›¸åŒçš„æ–‡æœ¬ä¿¡æ¯
3. âŒ **å•å±‚æ–‡æœ¬**: åªä½¿ç”¨ä¸€ä¸ªæ–‡æœ¬è¡¨ç¤º
4. âŒ **ç‹¬ç«‹å±‚æ¬¡**: ä¸åŒALIGNNå±‚çš„ä¸­æœŸèåˆäº’ä¸ç›¸å…³
5. âŒ **å›ºå®šæ®‹å·®**: æ®‹å·®æƒé‡å›ºå®šä¸º1.0

---

## ğŸ¯ æ”¹è¿›æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰

### ğŸ¥‡ æ”¹è¿›1: å¤šå¤´æ³¨æ„åŠ›é—¨æ§ï¼ˆMulti-Head Gatingï¼‰

#### åŸç†
ç”¨å¤šå¤´æ³¨æ„åŠ›æ›¿ä»£ç®€å•Sigmoidï¼Œè®©æ–‡æœ¬é€‰æ‹©æ€§åœ°å…³æ³¨ä¸åŒèŠ‚ç‚¹ç‰¹å¾ã€‚

#### å®ç°
```python
class MultiHeadGatedFusion(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›é—¨æ§èåˆ"""
    def __init__(self, node_dim=64, text_dim=64, num_heads=4, dropout=0.1):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = node_dim // num_heads

        # æŸ¥è¯¢ã€é”®ã€å€¼
        self.query = nn.Linear(node_dim, node_dim)  # èŠ‚ç‚¹æŸ¥è¯¢æ–‡æœ¬
        self.key = nn.Linear(text_dim, node_dim)    # æ–‡æœ¬ä½œä¸ºé”®
        self.value = nn.Linear(text_dim, node_dim)  # æ–‡æœ¬ä½œä¸ºå€¼

        # é—¨æ§æƒé‡ï¼ˆå¤šå¤´ï¼‰
        self.gate_heads = nn.ModuleList([
            nn.Sequential(
                nn.Linear(node_dim + text_dim, node_dim),
                nn.Sigmoid()
            ) for _ in range(num_heads)
        ])

        # èåˆå¤šå¤´ç»“æœ
        self.fusion = nn.Linear(node_dim * num_heads, node_dim)

    def forward(self, node_feat, text_feat, batch_num_nodes):
        # å¹¿æ’­æ–‡æœ¬ç‰¹å¾
        text_broadcasted = broadcast_text(text_feat, batch_num_nodes)

        # å¤šå¤´é—¨æ§
        head_outputs = []
        for i, gate in enumerate(self.gate_heads):
            gate_weight = gate(torch.cat([node_feat, text_broadcasted], dim=-1))
            head_output = gate_weight * text_broadcasted
            head_outputs.append(head_output)

        # èåˆå¤šå¤´
        fused = self.fusion(torch.cat(head_outputs, dim=-1))
        return node_feat + fused
```

#### ä¼˜åŠ¿
- âœ… ä¸åŒå¤´å…³æ³¨æ–‡æœ¬çš„ä¸åŒæ–¹é¢
- âœ… æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›
- âœ… ç±»ä¼¼äºTransformerçš„æ³¨æ„åŠ›æœºåˆ¶

#### é¢„æœŸæå‡
**+2-4% MAE**

---

### ğŸ¥ˆ æ”¹è¿›2: å±‚æ¬¡åŒ–æ–‡æœ¬ç‰¹å¾ï¼ˆHierarchical Text Featuresï¼‰

#### åŸç†
æå–å¤šå°ºåº¦æ–‡æœ¬ç‰¹å¾ï¼ˆå…¨å±€/åŠå…¨å±€/å±€éƒ¨ï¼‰ï¼Œåœ¨ä¸åŒå±‚æ³¨å…¥ä¸åŒç²’åº¦çš„ä¿¡æ¯ã€‚

#### å®ç°
```python
class HierarchicalMiddleFusion(nn.Module):
    """å±‚æ¬¡åŒ–ä¸­æœŸèåˆ"""
    def __init__(self, node_dim=64, text_dim=768, layer_id=0, total_layers=4):
        super().__init__()
        self.layer_id = layer_id

        # å¤šå°ºåº¦æ–‡æœ¬æå–å™¨
        self.global_extractor = nn.Linear(text_dim, node_dim)      # å…¨å±€ç‰¹å¾
        self.semi_global_extractor = nn.Linear(text_dim, node_dim) # åŠå…¨å±€
        self.local_extractor = nn.Linear(text_dim, node_dim)       # å±€éƒ¨

        # æ ¹æ®å±‚æ¬¡é€‰æ‹©æ–‡æœ¬ç²’åº¦çš„æƒé‡
        # æµ…å±‚ï¼šå…¨å±€ > åŠå…¨å±€ > å±€éƒ¨
        # æ·±å±‚ï¼šå±€éƒ¨ > åŠå…¨å±€ > å…¨å±€
        ratio = layer_id / (total_layers - 1)  # 0.0 -> 1.0

        self.global_weight = nn.Parameter(torch.tensor(1.0 - ratio))
        self.semi_global_weight = nn.Parameter(torch.tensor(0.5))
        self.local_weight = nn.Parameter(torch.tensor(ratio))

        # é—¨æ§
        self.gate = nn.Sequential(
            nn.Linear(node_dim * 2, node_dim),
            nn.Sigmoid()
        )

    def forward(self, node_feat, text_feat, batch_num_nodes):
        # æå–å¤šå°ºåº¦æ–‡æœ¬ç‰¹å¾
        global_feat = self.global_extractor(text_feat)      # [batch, node_dim]
        semi_global_feat = self.semi_global_extractor(text_feat)
        local_feat = self.local_extractor(text_feat)

        # åŠ æƒç»„åˆï¼ˆå¯å­¦ä¹ æƒé‡ï¼‰
        weights = F.softmax(torch.stack([
            self.global_weight,
            self.semi_global_weight,
            self.local_weight
        ]), dim=0)

        text_multi_scale = (
            weights[0] * global_feat +
            weights[1] * semi_global_feat +
            weights[2] * local_feat
        )

        # å¹¿æ’­å¹¶èåˆ
        text_broadcasted = broadcast_text(text_multi_scale, batch_num_nodes)
        gate_weight = self.gate(torch.cat([node_feat, text_broadcasted], dim=-1))

        return node_feat + gate_weight * text_broadcasted
```

#### ä¼˜åŠ¿
- âœ… æµ…å±‚æ³¨å…¥å…¨å±€ä¿¡æ¯ï¼ˆç»“æ„ã€å¯¹ç§°æ€§ï¼‰
- âœ… æ·±å±‚æ³¨å…¥å±€éƒ¨ä¿¡æ¯ï¼ˆé”®é•¿ã€è§’åº¦ï¼‰
- âœ… è‡ªé€‚åº”è°ƒæ•´ç²’åº¦æƒé‡

#### é¢„æœŸæå‡
**+3-5% MAE**

---

### ğŸ¥‰ æ”¹è¿›3: åŠ¨æ€é—¨æ§ï¼ˆDynamic Gatingï¼‰

#### åŸç†
è®©é—¨æ§å¼ºåº¦ä¾èµ–äºèŠ‚ç‚¹çš„é‡è¦æ€§ï¼Œé‡è¦èŠ‚ç‚¹è·å¾—æ›´å¤šæ–‡æœ¬ä¿¡æ¯ã€‚

#### å®ç°
```python
class DynamicGatedFusion(nn.Module):
    """åŠ¨æ€é—¨æ§èåˆ"""
    def __init__(self, node_dim=64, text_dim=64, dropout=0.1):
        super().__init__()

        # èŠ‚ç‚¹é‡è¦æ€§é¢„æµ‹å™¨
        self.importance_predictor = nn.Sequential(
            nn.Linear(node_dim, node_dim // 2),
            nn.ReLU(),
            nn.Linear(node_dim // 2, 1),
            nn.Sigmoid()
        )

        # æ–‡æœ¬å˜æ¢
        self.text_transform = nn.Linear(text_dim, node_dim)

        # åŠ¨æ€é—¨æ§ï¼ˆä¾èµ–èŠ‚ç‚¹é‡è¦æ€§ï¼‰
        self.gate_base = nn.Sequential(
            nn.Linear(node_dim * 2, node_dim),
            nn.Sigmoid()
        )

        # å¯å­¦ä¹ çš„é—¨æ§è°ƒåˆ¶å› å­
        self.gate_modulation = nn.Parameter(torch.tensor(1.0))

    def forward(self, node_feat, text_feat, batch_num_nodes):
        # é¢„æµ‹èŠ‚ç‚¹é‡è¦æ€§
        importance = self.importance_predictor(node_feat)  # [total_nodes, 1]

        # æ–‡æœ¬å˜æ¢å’Œå¹¿æ’­
        text_transformed = self.text_transform(text_feat)
        text_broadcasted = broadcast_text(text_transformed, batch_num_nodes)

        # åŸºç¡€é—¨æ§
        gate_base = self.gate_base(torch.cat([node_feat, text_broadcasted], dim=-1))

        # é‡è¦æ€§è°ƒåˆ¶é—¨æ§
        gate_modulated = gate_base * (1.0 + importance * self.gate_modulation)

        # èåˆ
        fused = node_feat + gate_modulated * text_broadcasted
        return fused
```

#### ä¼˜åŠ¿
- âœ… é‡è¦èŠ‚ç‚¹ï¼ˆæ´»æ€§ä½ç‚¹ï¼‰è·å¾—æ›´å¤šæ–‡æœ¬ä¿¡æ¯
- âœ… ä¸é‡è¦èŠ‚ç‚¹å‡å°‘æ–‡æœ¬å¹²æ‰°
- âœ… è‡ªé€‚åº”è°ƒæ•´èåˆå¼ºåº¦

#### é¢„æœŸæå‡
**+2-3% MAE**

---

### 4ï¸âƒ£ æ”¹è¿›4: æ®‹å·®ç¼©æ”¾å­¦ä¹ ï¼ˆLearnable Residual Scalingï¼‰

#### åŸç†
å­¦ä¹ èŠ‚ç‚¹ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾çš„æœ€ä¼˜æ®‹å·®æƒé‡ã€‚

#### å®ç°
```python
class ResidualScalingFusion(nn.Module):
    """æ®‹å·®ç¼©æ”¾èåˆ"""
    def __init__(self, node_dim=64, text_dim=64, initial_node_scale=1.0, initial_text_scale=12.0):
        super().__init__()

        # å¯å­¦ä¹ çš„æ®‹å·®æƒé‡
        self.node_scale = nn.Parameter(torch.tensor(initial_node_scale))
        self.text_scale = nn.Parameter(torch.tensor(initial_text_scale))

        # æ–‡æœ¬å˜æ¢
        self.text_transform = nn.Linear(text_dim, node_dim)

        # é—¨æ§
        self.gate = nn.Sequential(
            nn.Linear(node_dim * 2, node_dim),
            nn.Sigmoid()
        )

        self.layer_norm = nn.LayerNorm(node_dim)

    def forward(self, node_feat, text_feat, batch_num_nodes):
        # æ–‡æœ¬å˜æ¢
        text_transformed = self.text_transform(text_feat)
        text_broadcasted = broadcast_text(text_transformed, batch_num_nodes)

        # é—¨æ§
        gate_weight = self.gate(torch.cat([node_feat, text_broadcasted], dim=-1))

        # æ®‹å·®ç¼©æ”¾èåˆ
        fused = (
            self.node_scale * node_feat +
            self.text_scale * gate_weight * text_broadcasted
        )

        return self.layer_norm(fused)
```

#### ä¼˜åŠ¿
- âœ… è‡ªåŠ¨å­¦ä¹ èŠ‚ç‚¹å’Œæ–‡æœ¬çš„æœ€ä¼˜æƒé‡
- âœ… æ›¿ä»£å›ºå®šçš„1.0æ®‹å·®æƒé‡
- âœ… å¯ä»¥æ ¹æ®æ•°æ®åŠ¨æ€è°ƒæ•´

#### é¢„æœŸæå‡
**+1-3% MAE**

---

### 5ï¸âƒ£ æ”¹è¿›5: SENeté£æ ¼çš„é€šé“æ³¨æ„åŠ›ï¼ˆChannel Attentionï¼‰

#### åŸç†
è®©æ¨¡å‹å­¦ä¹ å“ªäº›ç‰¹å¾ç»´åº¦æ›´é‡è¦ã€‚

#### å®ç°
```python
class ChannelAttentionFusion(nn.Module):
    """é€šé“æ³¨æ„åŠ›èåˆ"""
    def __init__(self, node_dim=64, text_dim=64, reduction=4):
        super().__init__()

        # æ–‡æœ¬å˜æ¢
        self.text_transform = nn.Linear(text_dim, node_dim)

        # é€šé“æ³¨æ„åŠ›æ¨¡å—ï¼ˆSENeté£æ ¼ï¼‰
        self.channel_attention = nn.Sequential(
            nn.Linear(node_dim, node_dim // reduction),
            nn.ReLU(),
            nn.Linear(node_dim // reduction, node_dim),
            nn.Sigmoid()
        )

        # ç©ºé—´é—¨æ§
        self.spatial_gate = nn.Sequential(
            nn.Linear(node_dim * 2, node_dim),
            nn.Sigmoid()
        )

    def forward(self, node_feat, text_feat, batch_num_nodes):
        # æ–‡æœ¬å˜æ¢
        text_transformed = self.text_transform(text_feat)
        text_broadcasted = broadcast_text(text_transformed, batch_num_nodes)

        # é€šé“æ³¨æ„åŠ›ï¼ˆå¯¹æ–‡æœ¬ç‰¹å¾ï¼‰
        channel_weight = self.channel_attention(text_broadcasted)  # [nodes, node_dim]
        text_reweighted = text_broadcasted * channel_weight

        # ç©ºé—´é—¨æ§
        spatial_gate = self.spatial_gate(torch.cat([node_feat, text_reweighted], dim=-1))

        # èåˆ
        return node_feat + spatial_gate * text_reweighted
```

#### ä¼˜åŠ¿
- âœ… å­¦ä¹ å“ªäº›ç‰¹å¾ç»´åº¦é‡è¦
- âœ… æŠ‘åˆ¶å†—ä½™ç‰¹å¾
- âœ… å¢å¼ºæœ‰æ•ˆç‰¹å¾

#### é¢„æœŸæå‡
**+2-4% MAE**

---

### 6ï¸âƒ£ æ”¹è¿›6: è·¨å±‚ä¿¡æ¯ä¼ é€’ï¼ˆCross-Layer Information Flowï¼‰

#### åŸç†
ä¸åŒå±‚çš„ä¸­æœŸèåˆæ¨¡å—å…±äº«ä¿¡æ¯ï¼Œå¢å¼ºä¸€è‡´æ€§ã€‚

#### å®ç°
```python
class CrossLayerMiddleFusion(nn.Module):
    """è·¨å±‚ä¿¡æ¯ä¼ é€’çš„ä¸­æœŸèåˆ"""
    def __init__(self, node_dim=64, text_dim=64, layer_id=0, shared_memory_dim=32):
        super().__init__()
        self.layer_id = layer_id

        # å…±äº«è®°å¿†ï¼ˆè·¨å±‚ï¼‰
        if not hasattr(CrossLayerMiddleFusion, 'shared_memory'):
            CrossLayerMiddleFusion.shared_memory = None

        # è®°å¿†å†™å…¥
        self.memory_writer = nn.Linear(node_dim, shared_memory_dim)

        # è®°å¿†è¯»å–
        self.memory_reader = nn.Linear(shared_memory_dim, node_dim)

        # æ–‡æœ¬å˜æ¢
        self.text_transform = nn.Linear(text_dim, node_dim)

        # é—¨æ§
        self.gate = nn.Sequential(
            nn.Linear(node_dim * 3, node_dim),  # node + text + memory
            nn.Sigmoid()
        )

    def forward(self, node_feat, text_feat, batch_num_nodes):
        batch_size = text_feat.size(0)

        # è¯»å–ä¸Šä¸€å±‚çš„è®°å¿†
        if CrossLayerMiddleFusion.shared_memory is not None:
            memory_feat = self.memory_reader(CrossLayerMiddleFusion.shared_memory)
            memory_broadcasted = broadcast_text(memory_feat, batch_num_nodes)
        else:
            memory_broadcasted = torch.zeros_like(node_feat)

        # æ–‡æœ¬å˜æ¢
        text_transformed = self.text_transform(text_feat)
        text_broadcasted = broadcast_text(text_transformed, batch_num_nodes)

        # ä¸‰è·¯èåˆï¼šèŠ‚ç‚¹ + æ–‡æœ¬ + è®°å¿†
        gate_weight = self.gate(torch.cat([
            node_feat,
            text_broadcasted,
            memory_broadcasted
        ], dim=-1))

        fused = node_feat + gate_weight * (text_broadcasted + 0.5 * memory_broadcasted)

        # æ›´æ–°è®°å¿†ï¼ˆå…¨å±€æ± åŒ–ï¼‰
        # æŒ‰batchåˆ†ç»„æ± åŒ–
        fused_list = []
        offset = 0
        for num_nodes in batch_num_nodes:
            fused_list.append(fused[offset:offset+num_nodes].mean(dim=0))
            offset += num_nodes
        fused_pooled = torch.stack(fused_list)  # [batch, node_dim]

        CrossLayerMiddleFusion.shared_memory = self.memory_writer(fused_pooled)

        return fused
```

#### ä¼˜åŠ¿
- âœ… æµ…å±‚å’Œæ·±å±‚èåˆäº’ç›¸åè°ƒ
- âœ… å¢å¼ºå…¨å±€ä¸€è‡´æ€§
- âœ… å‡å°‘ä¿¡æ¯ä¸¢å¤±

#### é¢„æœŸæå‡
**+2-3% MAE**

---

### 7ï¸âƒ£ æ”¹è¿›7: å¯¹æ¯”å­¦ä¹ å¢å¼ºï¼ˆContrastive Enhancementï¼‰

#### åŸç†
è®©æ–‡æœ¬-å›¾èåˆåçš„ç‰¹å¾æ›´å…·åˆ¤åˆ«æ€§ã€‚

#### å®ç°
```python
class ContrastiveMiddleFusion(nn.Module):
    """å¯¹æ¯”å­¦ä¹ å¢å¼ºçš„ä¸­æœŸèåˆ"""
    def __init__(self, node_dim=64, text_dim=64, temperature=0.1):
        super().__init__()
        self.temperature = temperature

        # æ–‡æœ¬å˜æ¢
        self.text_transform = nn.Linear(text_dim, node_dim)

        # æŠ•å½±å¤´ï¼ˆç”¨äºå¯¹æ¯”å­¦ä¹ ï¼‰
        self.projection = nn.Sequential(
            nn.Linear(node_dim, node_dim),
            nn.ReLU(),
            nn.Linear(node_dim, node_dim // 2)
        )

        # é—¨æ§
        self.gate = nn.Sequential(
            nn.Linear(node_dim * 2, node_dim),
            nn.Sigmoid()
        )

    def forward(self, node_feat, text_feat, batch_num_nodes, compute_loss=False):
        # æ–‡æœ¬å˜æ¢
        text_transformed = self.text_transform(text_feat)
        text_broadcasted = broadcast_text(text_transformed, batch_num_nodes)

        # é—¨æ§èåˆ
        gate_weight = self.gate(torch.cat([node_feat, text_broadcasted], dim=-1))
        fused = node_feat + gate_weight * text_broadcasted

        if compute_loss:
            # å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼ˆèåˆå‰åçš„ä¸€è‡´æ€§ï¼‰
            node_proj = self.projection(node_feat)
            fused_proj = self.projection(fused)

            # InfoNCE loss
            sim = F.cosine_similarity(node_proj, fused_proj, dim=-1)
            loss = -torch.log(torch.exp(sim / self.temperature).mean())

            return fused, loss
        else:
            return fused
```

#### ä¼˜åŠ¿
- âœ… å¢å¼ºèåˆç‰¹å¾çš„åˆ¤åˆ«æ€§
- âœ… ä¿æŒèŠ‚ç‚¹å’Œæ–‡æœ¬çš„è¯­ä¹‰ä¸€è‡´æ€§
- âœ… æ­£åˆ™åŒ–ä½œç”¨

#### é¢„æœŸæå‡
**+1-2% MAE**

---

## ğŸ“Š æ”¹è¿›æ–¹æ¡ˆå¯¹æ¯”

| æ”¹è¿›æ–¹æ¡ˆ | å¤æ‚åº¦ | å‚æ•°å¢åŠ  | é¢„æœŸMAEæå‡ | å®ç°éš¾åº¦ | æ¨èä¼˜å…ˆçº§ |
|---------|--------|---------|------------|---------|-----------|
| **å¤šå¤´æ³¨æ„åŠ›é—¨æ§** | â­â­â­ | +30% | +2-4% | ä¸­ | ğŸ¥‡ **1** |
| **å±‚æ¬¡åŒ–æ–‡æœ¬ç‰¹å¾** | â­â­â­â­ | +50% | +3-5% | ä¸­-é«˜ | ğŸ¥ˆ **2** |
| **åŠ¨æ€é—¨æ§** | â­â­ | +15% | +2-3% | ä½ | ğŸ¥‰ **3** |
| **æ®‹å·®ç¼©æ”¾å­¦ä¹ ** | â­ | +0.1% | +1-3% | ä½ | **4** |
| **é€šé“æ³¨æ„åŠ›** | â­â­ | +20% | +2-4% | ä½-ä¸­ | **5** |
| **è·¨å±‚ä¿¡æ¯ä¼ é€’** | â­â­â­â­ | +25% | +2-3% | é«˜ | **6** |
| **å¯¹æ¯”å­¦ä¹ å¢å¼º** | â­â­â­ | +30% | +1-2% | ä¸­ | **7** |

---

## ğŸ¯ æ¨èå®æ–½ç­–ç•¥

### é˜¶æ®µ1: å¿«é€Ÿè§æ•ˆï¼ˆ1-2å‘¨ï¼‰

å®æ–½æ”¹è¿›4ï¼ˆæ®‹å·®ç¼©æ”¾ï¼‰+ æ”¹è¿›3ï¼ˆåŠ¨æ€é—¨æ§ï¼‰

```python
# ç»„åˆå®ç°
class ImprovedMiddleFusion_Stage1(nn.Module):
    """ç¬¬ä¸€é˜¶æ®µæ”¹è¿›ï¼šæ®‹å·®ç¼©æ”¾ + åŠ¨æ€é—¨æ§"""
    def __init__(self, node_dim=64, text_dim=768,
                 initial_node_scale=1.0,
                 initial_text_scale=12.0):
        super().__init__()

        # æ®‹å·®ç¼©æ”¾
        self.node_scale = nn.Parameter(torch.tensor(initial_node_scale))
        self.text_scale = nn.Parameter(torch.tensor(initial_text_scale))

        # æ–‡æœ¬å˜æ¢
        self.text_transform = nn.Sequential(
            nn.Linear(text_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, node_dim)
        )

        # èŠ‚ç‚¹é‡è¦æ€§é¢„æµ‹
        self.importance = nn.Sequential(
            nn.Linear(node_dim, node_dim // 2),
            nn.ReLU(),
            nn.Linear(node_dim // 2, 1),
            nn.Sigmoid()
        )

        # åŠ¨æ€é—¨æ§
        self.gate = nn.Sequential(
            nn.Linear(node_dim * 2, node_dim),
            nn.Sigmoid()
        )

        self.layer_norm = nn.LayerNorm(node_dim)

    def forward(self, node_feat, text_feat, batch_num_nodes):
        # èŠ‚ç‚¹é‡è¦æ€§
        importance = self.importance(node_feat)

        # æ–‡æœ¬å˜æ¢
        text_transformed = self.text_transform(text_feat)
        text_broadcasted = broadcast_text(text_transformed, batch_num_nodes)

        # é—¨æ§
        gate_weight = self.gate(torch.cat([node_feat, text_broadcasted], dim=-1))

        # é‡è¦æ€§è°ƒåˆ¶
        gate_modulated = gate_weight * (1.0 + importance)

        # æ®‹å·®ç¼©æ”¾èåˆ
        fused = (
            self.node_scale * node_feat +
            self.text_scale * gate_modulated * text_broadcasted
        )

        return self.layer_norm(fused)
```

**é¢„æœŸæå‡**: +3-6% MAE

---

### é˜¶æ®µ2: æ·±åº¦ä¼˜åŒ–ï¼ˆ2-4å‘¨ï¼‰

åŠ å…¥æ”¹è¿›1ï¼ˆå¤šå¤´æ³¨æ„åŠ›é—¨æ§ï¼‰

```python
class ImprovedMiddleFusion_Stage2(nn.Module):
    """ç¬¬äºŒé˜¶æ®µæ”¹è¿›ï¼šå¤šå¤´æ³¨æ„åŠ›é—¨æ§ + æ®‹å·®ç¼©æ”¾"""
    # ç»„åˆé˜¶æ®µ1 + å¤šå¤´æ³¨æ„åŠ›
    # è¯¦ç»†å®ç°è§ä¸Šæ–‡
```

**é¢„æœŸæå‡**: +5-9% MAE

---

### é˜¶æ®µ3: å…¨é¢å‡çº§ï¼ˆ4-6å‘¨ï¼‰

åŠ å…¥æ”¹è¿›2ï¼ˆå±‚æ¬¡åŒ–æ–‡æœ¬ï¼‰+ æ”¹è¿›5ï¼ˆé€šé“æ³¨æ„åŠ›ï¼‰

```python
class ImprovedMiddleFusion_Stage3(nn.Module):
    """ç¬¬ä¸‰é˜¶æ®µæ”¹è¿›ï¼šå®Œæ•´ç‰ˆ"""
    # ç»„åˆæ‰€æœ‰æ”¹è¿›
```

**é¢„æœŸæå‡**: +7-12% MAE

---

## ğŸ’¡ å¿«é€Ÿå®éªŒå»ºè®®

### å®éªŒA: æ®‹å·®ç¼©æ”¾ï¼ˆæœ€ç®€å•ï¼‰

åªéœ€ä¿®æ”¹å½“å‰MiddleFusionModuleï¼š

```python
# åœ¨ __init__ ä¸­æ·»åŠ 
self.node_scale = nn.Parameter(torch.tensor(1.0))

# åœ¨ forward çš„èåˆéƒ¨åˆ†æ”¹ä¸º
fused = self.node_scale * node_feat + self.text_scale * gate_weight * text_broadcasted
```

**å®æ–½æ—¶é—´**: 5åˆ†é’Ÿ
**é¢„æœŸæå‡**: +1-3% MAE

---

### å®éªŒB: åŠ¨æ€é—¨æ§ï¼ˆç®€å•ï¼‰

æ·»åŠ é‡è¦æ€§é¢„æµ‹å™¨ï¼š

```python
# åœ¨ __init__ ä¸­æ·»åŠ 
self.importance_predictor = nn.Sequential(
    nn.Linear(node_dim, node_dim // 2),
    nn.ReLU(),
    nn.Linear(node_dim // 2, 1),
    nn.Sigmoid()
)

# åœ¨ forward ä¸­
importance = self.importance_predictor(node_feat)
gate_weight = self.gate(...) * (1.0 + importance)
```

**å®æ–½æ—¶é—´**: 10åˆ†é’Ÿ
**é¢„æœŸæå‡**: +2-3% MAE

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

### å‡†å¤‡é˜¶æ®µ
- [ ] å¤‡ä»½å½“å‰ä»£ç 
- [ ] åˆ›å»ºæ–°çš„å®éªŒåˆ†æ”¯
- [ ] å‡†å¤‡å¯¹æ¯”å®éªŒé…ç½®

### å®æ–½é˜¶æ®µ1ï¼ˆå¿«é€Ÿæ”¹è¿›ï¼‰
- [ ] æ·»åŠ æ®‹å·®ç¼©æ”¾ï¼ˆnode_scaleå‚æ•°ï¼‰
- [ ] æ·»åŠ åŠ¨æ€é—¨æ§ï¼ˆimportance predictorï¼‰
- [ ] æµ‹è¯•forwardæ­£å¸¸è¿è¡Œ
- [ ] è¿è¡Œå°è§„æ¨¡è®­ç»ƒéªŒè¯

### å®æ–½é˜¶æ®µ2ï¼ˆæ·±åº¦ä¼˜åŒ–ï¼‰
- [ ] å®ç°å¤šå¤´æ³¨æ„åŠ›é—¨æ§
- [ ] é›†æˆåˆ°ç°æœ‰æ¨¡å—
- [ ] æ¶ˆèå®éªŒå¯¹æ¯”

### å®æ–½é˜¶æ®µ3ï¼ˆå…¨é¢å‡çº§ï¼‰
- [ ] å®ç°å±‚æ¬¡åŒ–æ–‡æœ¬ç‰¹å¾
- [ ] å®ç°é€šé“æ³¨æ„åŠ›
- [ ] å®Œæ•´æ€§èƒ½è¯„ä¼°

---

## ğŸ”¬ æ¶ˆèå®éªŒè®¾è®¡

å»ºè®®æµ‹è¯•é¡ºåºï¼š

1. **åŸºçº¿**: å½“å‰MiddleFusion (initial_scale=12.0)
2. **+æ®‹å·®ç¼©æ”¾**: æ·»åŠ node_scale
3. **+åŠ¨æ€é—¨æ§**: æ·»åŠ importanceè°ƒåˆ¶
4. **+å¤šå¤´æ³¨æ„åŠ›**: æ›¿æ¢ç®€å•é—¨æ§
5. **+å±‚æ¬¡åŒ–æ–‡æœ¬**: æ·»åŠ å¤šå°ºåº¦æ–‡æœ¬
6. **å®Œæ•´ç‰ˆ**: æ‰€æœ‰æ”¹è¿›ç»„åˆ

æ¯ä¸ªæ”¹è¿›å•ç‹¬æµ‹è¯•ï¼Œç„¶åé€æ­¥ç»„åˆã€‚

---

## ğŸŠ æ€»ç»“

### æœ€æ¨èçš„ç»„åˆï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰

**ç»„åˆA**: æ®‹å·®ç¼©æ”¾ + åŠ¨æ€é—¨æ§ + é€šé“æ³¨æ„åŠ›
- å®ç°éš¾åº¦: â­â­
- å‚æ•°å¢åŠ : +35%
- é¢„æœŸæå‡: **+5-8% MAE**
- å®æ–½æ—¶é—´: 1-2å¤©

**ç»„åˆB**: å¤šå¤´æ³¨æ„åŠ›é—¨æ§ + å±‚æ¬¡åŒ–æ–‡æœ¬
- å®ç°éš¾åº¦: â­â­â­â­
- å‚æ•°å¢åŠ : +80%
- é¢„æœŸæå‡: **+7-12% MAE**
- å®æ–½æ—¶é—´: 1-2å‘¨

### æ‚¨çš„ä¸‹ä¸€æ­¥

æˆ‘å»ºè®®ä»**å®éªŒAï¼ˆæ®‹å·®ç¼©æ”¾ï¼‰**å¼€å§‹ï¼Œè¿™æ˜¯æœ€ç®€å•çš„æ”¹è¿›ï¼Œåªéœ€5åˆ†é’Ÿå®ç°ï¼Œå°±èƒ½è·å¾—1-3%çš„æå‡ï¼

éœ€è¦æˆ‘å¸®æ‚¨å®ç°å“ªä¸ªæ”¹è¿›æ–¹æ¡ˆï¼Ÿ
