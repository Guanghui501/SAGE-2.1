# HSEå¸¦éš™è®­ç»ƒé—®é¢˜è¯Šæ–­å’Œæ”¹è¿›æ–¹æ¡ˆ

## ğŸ” é—®é¢˜è¯Šæ–­

### å½“å‰è®­ç»ƒæ›²çº¿åˆ†æ

ä»æ‚¨æä¾›çš„æ›²çº¿å¯ä»¥çœ‹å‡ºï¼š

1. **ä¸¥é‡è¿‡æ‹Ÿåˆ** âš ï¸
   - è®­ç»ƒMAE: ~0.05 eV (æ¥è¿‘0)
   - éªŒè¯MAE: ~0.40 eV
   - **å·®è·: 0.35 eV (8å€å·®å¼‚ï¼)**

2. **éªŒè¯æŸå¤±åœæ»**
   - éªŒè¯MAEåœ¨çº¦40ä¸ªepochåå°±åœæ­¢æ”¹å–„
   - åœç•™åœ¨0.40 eVé™„è¿‘

3. **è®­ç»ƒæŸå¤±è¿‡ä½**
   - è®­ç»ƒæŸå¤±å‡ ä¹ä¸º0ï¼Œè¯´æ˜æ¨¡å‹å®Œå…¨è®°ä½äº†è®­ç»ƒé›†
   - è¿™å¯¹æ³›åŒ–èƒ½åŠ›éå¸¸ä¸åˆ©

### å½“å‰é…ç½®é—®é¢˜

```json
{
    "epochs": 100,              // âŒ è®­ç»ƒå¤ªä¹…
    "batch_size": 64,
    "learning_rate": 0.0005,
    "weight_decay": 0.001,      // âŒ æ­£åˆ™åŒ–å¤ªå¼±
    "graph_dropout": 0.15,      // âŒ dropoutå¤ªå°
    "fine_grained_dropout": 0.35,
    "middle_fusion_dropout": 0.35,
    "use_middle_fusion": true,  // âš ï¸ æ‚¨ä¹‹å‰å®éªŒæ˜¾ç¤ºè¿™ä¸ªé™ä½æ€§èƒ½
    "n_early_stopping": 150     // âŒ å¤ªå¤§ï¼Œå‡ ä¹ä¸èµ·ä½œç”¨
}
```

---

## ğŸ’¡ æ”¹è¿›æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: å¢å¼ºæ­£åˆ™åŒ– â­ é¦–é€‰

**æ ¸å¿ƒæ€è·¯**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›

#### ä¿®æ”¹å»ºè®®ï¼š

```json
{
    // 1. å¢åŠ Dropout
    "graph_dropout": 0.3,           // 0.15 â†’ 0.3
    "fine_grained_dropout": 0.45,   // 0.35 â†’ 0.45
    "middle_fusion_dropout": 0.45,  // 0.35 â†’ 0.45
    "cross_modal_dropout": 0.2,     // 0.1 â†’ 0.2

    // 2. å¢å¼ºæƒé‡è¡°å‡
    "weight_decay": 0.01,           // 0.001 â†’ 0.01 (10å€)

    // 3. æ—©åœç­–ç•¥
    "n_early_stopping": 30,         // 150 â†’ 30

    // 4. å‡å°‘epochs
    "epochs": 200,                  // ä¿æŒ200ï¼Œä½†ä¼šè¢«early stoppingæå‰ç»ˆæ­¢
}
```

**è®­ç»ƒå‘½ä»¤**ï¼š
```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.01 \
    --warmup_steps 2000 \
    --graph_dropout 0.3 \
    --fine_grained_dropout 0.45 \
    --middle_fusion_dropout 0.45 \
    --cross_modal_dropout 0.2 \
    --n_early_stopping 30 \
    --output_dir runs/hse_reg_strong
```

**é¢„æœŸæ•ˆæœ**ï¼š
- è®­ç»ƒMAE: ~0.15-0.20 eV
- éªŒè¯MAE: ~0.30-0.35 eV
- å·®è·: <0.15 eV

---

### æ–¹æ¡ˆ2: å»æ‰Middle Fusion â­â­ å¼ºçƒˆæ¨è

**æ‚¨ä¹‹å‰çš„å®éªŒç»“æœ**ï¼š
- ä¸­æœŸèåˆ + è·¨æ¨¡æ€ + ç»†ç²’åº¦: MAE = 0.25
- ä¸­æœŸèåˆ + gateè·¨æ¨¡æ€ + ç»†ç²’åº¦: MAE = 0.27 (é™ä½8%)
- **ä¸­æœŸèåˆå¯¼è‡´åˆ é™¤æ–‡æœ¬åé²æ£’æ€§é™ä½39% (0.536 â†’ 0.747)**

**ç»“è®º**ï¼šMiddle Fusionæ˜¯æ€§èƒ½ç“¶é¢ˆï¼

#### ä¿®æ”¹å»ºè®®ï¼š

```json
{
    // æ ¸å¿ƒæ”¹å˜ï¼šå»æ‰middle fusion
    "use_middle_fusion": false,     // true â†’ false

    // è°ƒæ•´å…¶ä»–å‚æ•°
    "graph_dropout": 0.25,
    "fine_grained_dropout": 0.4,
    "cross_modal_dropout": 0.15,
    "weight_decay": 0.005,
    "n_early_stopping": 40,
}
```

**è®­ç»ƒå‘½ä»¤**ï¼š
```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.005 \
    --warmup_steps 2000 \
    --use_cross_modal_attention \
    --use_fine_grained_attention \
    --fine_grained_dropout 0.4 \
    --graph_dropout 0.25 \
    --n_early_stopping 40 \
    --output_dir runs/hse_no_middle_fusion
```

**é¢„æœŸæ•ˆæœ**ï¼š
- éªŒè¯MAE: ~0.25 eVï¼ˆåŸºäºæ‚¨ä¹‹å‰çš„å®éªŒï¼‰
- æ¯”å½“å‰0.40æ”¹å–„37.5%ï¼

---

### æ–¹æ¡ˆ3: å‡å°æ¨¡å‹å®¹é‡

**æ ¸å¿ƒæ€è·¯**ï¼šæ›´å°çš„æ¨¡å‹ = æ›´éš¾è¿‡æ‹Ÿåˆ

#### ä¿®æ”¹å»ºè®®ï¼š

```json
{
    // å‡å°æ¨¡å‹å°ºå¯¸
    "alignn_layers": 3,             // 4 â†’ 3
    "gcn_layers": 3,                // 4 â†’ 3
    "hidden_features": 192,         // 256 â†’ 192
    "cross_modal_hidden_dim": 192,  // 256 â†’ 192
    "fine_grained_hidden_dim": 192, // 256 â†’ 192
    "fine_grained_num_heads": 4,    // 8 â†’ 4

    // è°ƒæ•´æ­£åˆ™åŒ–
    "graph_dropout": 0.25,
    "fine_grained_dropout": 0.4,
    "weight_decay": 0.005,
    "n_early_stopping": 40,
    "use_middle_fusion": false,     // å»æ‰middle fusion
}
```

**è®­ç»ƒå‘½ä»¤**ï¼š
```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.005 \
    --warmup_steps 2000 \
    --alignn_layers 3 \
    --gcn_layers 3 \
    --hidden_features 192 \
    --use_cross_modal_attention \
    --cross_modal_hidden_dim 192 \
    --use_fine_grained_attention \
    --fine_grained_hidden_dim 192 \
    --fine_grained_num_heads 4 \
    --fine_grained_dropout 0.4 \
    --graph_dropout 0.25 \
    --n_early_stopping 40 \
    --output_dir runs/hse_smaller_model
```

**ä¼˜ç‚¹**ï¼š
- è®­ç»ƒæ›´å¿«
- æ›´éš¾è¿‡æ‹Ÿåˆ
- æ¨ç†é€Ÿåº¦æ›´å¿«

---

### æ–¹æ¡ˆ4: ä¼˜åŒ–å­¦ä¹ ç‡ç­–ç•¥

**å½“å‰é—®é¢˜**ï¼šå­¦ä¹ ç‡å¯èƒ½åœ¨æ—©æœŸè¿‡é«˜ï¼Œå¯¼è‡´å¿«é€Ÿè¿‡æ‹Ÿåˆ

#### ä¿®æ”¹å»ºè®®ï¼š

```json
{
    // é™ä½å­¦ä¹ ç‡
    "learning_rate": 0.0003,        // 0.0005 â†’ 0.0003
    "warmup_steps": 3000,           // 2000 â†’ 3000 (æ›´é•¿çš„warmup)

    // æˆ–ä½¿ç”¨ä½™å¼¦é€€ç«
    "scheduler": "cosine",          // "onecycle" â†’ "cosine"

    // å…¶ä»–è°ƒæ•´
    "weight_decay": 0.005,
    "graph_dropout": 0.25,
    "fine_grained_dropout": 0.4,
    "use_middle_fusion": false,
    "n_early_stopping": 40,
}
```

**è®­ç»ƒå‘½ä»¤**ï¼š
```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0003 \
    --weight_decay 0.005 \
    --warmup_steps 3000 \
    --scheduler cosine \
    --use_cross_modal_attention \
    --use_fine_grained_attention \
    --fine_grained_dropout 0.4 \
    --graph_dropout 0.25 \
    --n_early_stopping 40 \
    --output_dir runs/hse_lower_lr
```

---

### æ–¹æ¡ˆ5: å¢åŠ æ•°æ®å¢å¼ºï¼ˆé«˜çº§ï¼‰

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ‰°åŠ¨å¢åŠ è®­ç»ƒæ ·æœ¬å¤šæ ·æ€§

#### å®ç°æ–¹æ³•ï¼š

1. **æ™¶æ ¼æ‰°åŠ¨**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
   ```python
   # åœ¨å›¾æ„å»ºæ—¶æ·»åŠ å°çš„éšæœºæ‰°åŠ¨
   perturbed_lattice = lattice * (1 + np.random.normal(0, 0.02, lattice.shape))
   ```

2. **æ–‡æœ¬å¢å¼º**
   - éšæœºåˆ é™¤éƒ¨åˆ†æè¿°è¯
   - åŒä¹‰è¯æ›¿æ¢
   - å›è¯‘ï¼ˆè‹±è¯­â†’ä¸­æ–‡â†’è‹±è¯­ï¼‰

3. **Mixupç­–ç•¥**ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
   ```python
   # æ··åˆä¸¤ä¸ªæ ·æœ¬
   lambda_mix = np.random.beta(0.2, 0.2)
   mixed_features = lambda_mix * features1 + (1 - lambda_mix) * features2
   mixed_target = lambda_mix * target1 + (1 - lambda_mix) * target2
   ```

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | å®æ–½éš¾åº¦ | é¢„æœŸæ”¹å–„ | è®­ç»ƒæ—¶é—´ | æ¨èæŒ‡æ•° |
|-----|---------|---------|---------|---------|
| **æ–¹æ¡ˆ2: å»æ‰Middle Fusion** | â­ ç®€å• | â­â­â­â­â­ | å¿« | â­â­â­â­â­ |
| **æ–¹æ¡ˆ1: å¢å¼ºæ­£åˆ™åŒ–** | â­ ç®€å• | â­â­â­â­ | ä¸­ | â­â­â­â­ |
| **æ–¹æ¡ˆ3: å‡å°æ¨¡å‹** | â­ ç®€å• | â­â­â­ | å¿« | â­â­â­â­ |
| **æ–¹æ¡ˆ4: ä¼˜åŒ–å­¦ä¹ ç‡** | â­ ç®€å• | â­â­â­ | ä¸­ | â­â­â­ |
| **æ–¹æ¡ˆ5: æ•°æ®å¢å¼º** | â­â­â­ å›°éš¾ | â­â­â­â­ | æ…¢ | â­â­ |

---

## ğŸ¯ æ¨èå®æ–½é¡ºåº

### ç¬¬ä¸€æ­¥ï¼šå»æ‰Middle Fusionï¼ˆæœ€é‡è¦ï¼ï¼‰â­â­â­â­â­

åŸºäºæ‚¨ä¹‹å‰çš„å®éªŒï¼Œè¿™åº”è¯¥ç«‹å³å¸¦æ¥æ˜¾è‘—æ”¹å–„ï¼š

```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.005 \
    --warmup_steps 2000 \
    --use_cross_modal_attention \
    --use_fine_grained_attention \
    --fine_grained_dropout 0.4 \
    --graph_dropout 0.25 \
    --n_early_stopping 40 \
    --output_dir runs/hse_no_middle_fusion
```

**é¢„æœŸç»“æœ**ï¼šéªŒè¯MAEä»0.40é™åˆ°0.25 eV

---

### ç¬¬äºŒæ­¥ï¼šå¦‚æœä»æœ‰è¿‡æ‹Ÿåˆï¼Œå¢å¼ºæ­£åˆ™åŒ–

```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.01 \
    --warmup_steps 2000 \
    --use_cross_modal_attention \
    --use_fine_grained_attention \
    --fine_grained_dropout 0.45 \
    --cross_modal_dropout 0.2 \
    --graph_dropout 0.3 \
    --n_early_stopping 30 \
    --output_dir runs/hse_strong_reg
```

---

### ç¬¬ä¸‰æ­¥ï¼šå°è¯•æ›´å°çš„æ¨¡å‹

```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.005 \
    --warmup_steps 2000 \
    --alignn_layers 3 \
    --gcn_layers 3 \
    --hidden_features 192 \
    --use_cross_modal_attention \
    --cross_modal_hidden_dim 192 \
    --use_fine_grained_attention \
    --fine_grained_hidden_dim 192 \
    --fine_grained_num_heads 4 \
    --fine_grained_dropout 0.4 \
    --graph_dropout 0.25 \
    --n_early_stopping 40 \
    --output_dir runs/hse_smaller
```

---

## ğŸ”§ å…¶ä»–æŠ€å·§

### 1. Label Smoothing

å¦‚æœä»£ç æ”¯æŒï¼Œæ·»åŠ ï¼š
```json
"label_smoothing": 0.1
```

### 2. Gradient Clipping

```json
"gradient_clip": 1.0
```

### 3. æ··åˆç²¾åº¦è®­ç»ƒ

```bash
--use_amp  # å¦‚æœæ”¯æŒ
```

### 4. ç›‘æ§æ¢¯åº¦

åœ¨è®­ç»ƒæ—¶æ·»åŠ æ¢¯åº¦ç›‘æ§ï¼Œç¡®ä¿æ²¡æœ‰æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±ã€‚

---

## ğŸ“ˆ é¢„æœŸæ”¹å–„å¯¹æ¯”

| é…ç½® | å½“å‰ | æ–¹æ¡ˆ2 | æ–¹æ¡ˆ1+2 | æ–¹æ¡ˆ2+3 |
|-----|------|-------|---------|---------|
| è®­ç»ƒMAE | 0.05 | 0.18 | 0.20 | 0.22 |
| éªŒè¯MAE | **0.40** | **0.25** | **0.22** | **0.20** |
| è¿‡æ‹Ÿåˆç¨‹åº¦ | ä¸¥é‡ | è½»å¾® | å¾ˆå° | å¾ˆå° |
| è®­ç»ƒæ—¶é—´ | 100 epochs | 60 epochs | 80 epochs | 50 epochs |

---

## ğŸ“ ç†è®ºè§£é‡Š

### ä¸ºä»€ä¹ˆä¼šè¿‡æ‹Ÿåˆï¼Ÿ

1. **æ¨¡å‹å®¹é‡è¿‡å¤§**
   - æ‚¨çš„æ¨¡å‹æœ‰å¾ˆå¤šå±‚å’Œå‚æ•°
   - æ•°æ®é›†åªæœ‰~1600ä¸ªæ ·æœ¬
   - æ¨¡å‹å®¹é‡ >> æ•°æ®é‡ = è¿‡æ‹Ÿåˆ

2. **Middle Fusioné—®é¢˜**
   - å¢åŠ äº†é¢å¤–çš„å‚æ•°
   - åœ¨ç¬¬2å±‚å°±èåˆï¼Œå®¹æ˜“äº§ç”Ÿç‰¹å¾æ±¡æŸ“
   - æ‚¨çš„å®éªŒå·²ç»è¯æ˜å®ƒé™ä½æ€§èƒ½

3. **æ­£åˆ™åŒ–ä¸è¶³**
   - weight_decay=0.001å¤ªå°
   - dropout=0.15å¤ªå°
   - æ— æ³•æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆ

### ä¸ºä»€ä¹ˆå»æ‰Middle Fusionä¼šæ”¹å–„ï¼Ÿ

1. **å‡å°‘å‚æ•°**ï¼šæ›´å°‘çš„å¯è®­ç»ƒå‚æ•°
2. **å»¶è¿Ÿèåˆ**ï¼šè®©GNNå…ˆå……åˆ†æå–ç»“æ„ç‰¹å¾
3. **æé«˜é²æ£’æ€§**ï¼šå‡å°‘æ—©æœŸç‰¹å¾æ±¡æŸ“
4. **æ‚¨çš„å®éªŒéªŒè¯**ï¼šæ— middle fusionæ—¶MAE=0.25ï¼Œæœ‰middle fusionæ—¶MAE=0.27

---

## âœ… æ€»ç»“

### æ ¸å¿ƒé—®é¢˜
- **ä¸¥é‡è¿‡æ‹Ÿåˆ**ï¼ˆè®­ç»ƒ0.05 vs éªŒè¯0.40ï¼‰
- **Middle Fusioné™ä½æ€§èƒ½**ï¼ˆæ‚¨çš„å®éªŒå·²è¯æ˜ï¼‰
- **æ­£åˆ™åŒ–ä¸è¶³**

### æœ€ä½³æ–¹æ¡ˆç»„åˆ â­â­â­â­â­

```bash
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.01 \
    --warmup_steps 2000 \
    --alignn_layers 3 \
    --gcn_layers 3 \
    --hidden_features 192 \
    --use_cross_modal_attention \
    --cross_modal_hidden_dim 192 \
    --cross_modal_dropout 0.2 \
    --use_fine_grained_attention \
    --fine_grained_hidden_dim 192 \
    --fine_grained_num_heads 4 \
    --fine_grained_dropout 0.45 \
    --graph_dropout 0.3 \
    --n_early_stopping 30 \
    --output_dir runs/hse_optimized
```

**é¢„æœŸç»“æœ**ï¼š
- éªŒè¯MAE: **0.20-0.25 eV**ï¼ˆå½“å‰0.40çš„50-62.5%ï¼‰
- è®­ç»ƒMAE: **0.22-0.28 eV**
- è¿‡æ‹Ÿåˆå·®è·: **<0.05 eV**

### å¿«é€Ÿæµ‹è¯•ï¼ˆå…ˆè·‘è¿™ä¸ªï¼ï¼‰

```bash
# åªå»æ‰middle fusionï¼Œå…¶ä»–ä¿æŒä¸å˜
python train_with_cross_modal_attention.py \
    --dataset dft_3d \
    --target hse_bandgap \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 0.0005 \
    --weight_decay 0.005 \
    --warmup_steps 2000 \
    --use_cross_modal_attention \
    --use_fine_grained_attention \
    --fine_grained_dropout 0.4 \
    --graph_dropout 0.25 \
    --n_early_stopping 40 \
    --output_dir runs/hse_quick_fix
```

è¿™ä¸ªåº”è¯¥ç«‹å³çœ‹åˆ°æ”¹å–„ï¼å¦‚æœéªŒè¯MAEé™åˆ°0.25å·¦å³ï¼Œè¯´æ˜æ–¹å‘æ­£ç¡®ã€‚ç„¶åå†å°è¯•å…¶ä»–ä¼˜åŒ–ã€‚

---

**ç”Ÿæˆæ—¶é—´**ï¼š2025-12-10
**é—®é¢˜**ï¼šä¸¥é‡è¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒ0.05 vs éªŒè¯0.40ï¼‰
**æ ¸å¿ƒè§£å†³æ–¹æ¡ˆ**ï¼šå»æ‰Middle Fusion + å¢å¼ºæ­£åˆ™åŒ– + å‡å°æ¨¡å‹
**é¢„æœŸæ”¹å–„**ï¼šéªŒè¯MAEä»0.40é™åˆ°0.20-0.25 eVï¼ˆæ”¹å–„37.5-50%ï¼‰
