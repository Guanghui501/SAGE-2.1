"""ä¿®å¤ä¸­æœŸèåˆçš„ç‰¹å¾å°ºåº¦ä¸åŒ¹é…é—®é¢˜

è¿™ä¸ªè„šæœ¬æä¾›äº†å¯¹ MiddleFusionModule çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œè§£å†³ï¼š
1. ç‰¹å¾å°ºåº¦ä¸åŒ¹é…ï¼ˆèŠ‚ç‚¹ç‰¹å¾ >> æ–‡æœ¬ç‰¹å¾ï¼‰
2. Gate å€¼ç¼ºä¹å¤šæ ·æ€§
3. ä½™å¼¦ç›¸ä¼¼åº¦è¿‡ä½

ä½¿ç”¨æ–¹æ³•:
1. å¤åˆ¶æ”¹è¿›çš„ MiddleFusionModule åˆ° models/alignn.py
2. é‡æ–°è®­ç»ƒæ¨¡å‹

æˆ–è€…ï¼š
ä½¿ç”¨è¿™ä¸ªè„šæœ¬åˆ›å»ºä¸€ä¸ª wrapper æ¥ä¿®å¤å·²æœ‰æ¨¡å‹ï¼ˆæ— éœ€é‡æ–°è®­ç»ƒï¼‰
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class ImprovedMiddleFusionModule(nn.Module):
    """æ”¹è¿›çš„ä¸­æœŸèåˆæ¨¡å—

    ä¸»è¦æ”¹è¿›ï¼š
    1. æ·»åŠ  LayerNorm å½’ä¸€åŒ–è¾“å…¥ç‰¹å¾ï¼ˆè§£å†³å°ºåº¦ä¸åŒ¹é…ï¼‰
    2. ä½¿ç”¨ Tanh æ›¿ä»£ Sigmoidï¼ˆæ›´å®½çš„æ¿€æ´»èŒƒå›´ï¼‰
    3. æ·»åŠ å¯å­¦ä¹ çš„æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶ gate æ•æ„Ÿåº¦ï¼‰
    4. æ”¹è¿› alpha æå–æ–¹å¼ï¼ˆä½¿ç”¨åŠ æƒå¹³å‡è€Œéç®€å•å¹³å‡ï¼‰
    """

    def __init__(self, node_dim=64, text_dim=64, hidden_dim=128, num_heads=2, dropout=0.1,
                 use_layer_norm=True, use_tanh_gate=False, gate_temperature=1.0):
        """åˆå§‹åŒ–æ”¹è¿›çš„ä¸­æœŸèåˆæ¨¡å—

        Args:
            node_dim: å›¾èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
            text_dim: æ–‡æœ¬ç‰¹å¾ç»´åº¦
            hidden_dim: éšè—å±‚ç»´åº¦
            num_heads: æ³¨æ„åŠ›å¤´æ•°ï¼ˆä¿ç•™ç”¨äºæœªæ¥æ‰©å±•ï¼‰
            dropout: Dropout ç‡
            use_layer_norm: æ˜¯å¦åœ¨ gate è¾“å…¥å‰ä½¿ç”¨ LayerNorm
            use_tanh_gate: æ˜¯å¦ä½¿ç”¨ Tanh æ›¿ä»£ Sigmoid
            gate_temperature: Gate æ¸©åº¦å‚æ•°ï¼ˆ>1 ä½¿åˆ†å¸ƒæ›´å¹³å¦ï¼Œ<1 ä½¿åˆ†å¸ƒæ›´å°–é”ï¼‰
        """
        super().__init__()
        self.node_dim = node_dim
        self.text_dim = text_dim
        self.hidden_dim = hidden_dim
        self.use_layer_norm = use_layer_norm
        self.use_tanh_gate = use_tanh_gate
        self.gate_temperature = gate_temperature

        # Text transformation
        self.text_transform = nn.Sequential(
            nn.Linear(text_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, node_dim)
        )

        # === æ”¹è¿› 1: æ·»åŠ  LayerNorm ===
        if use_layer_norm:
            self.gate_norm = nn.LayerNorm(node_dim * 2)

        # Gate mechanism
        self.gate = nn.Linear(node_dim + node_dim, node_dim)

        # === æ”¹è¿› 2: å¯é€‰çš„æ¿€æ´»å‡½æ•° ===
        if use_tanh_gate:
            self.gate_activation = nn.Tanh()
        else:
            self.gate_activation = nn.Sigmoid()

        self.layer_norm = nn.LayerNorm(node_dim)
        self.dropout = nn.Dropout(dropout)

        # === æ”¹è¿› 3: å¯å­¦ä¹ çš„ alpha æå–æƒé‡ ===
        # ç”¨äºä» [N, node_dim] çš„ gate_values æå–å•ä¸ª alpha å€¼
        self.alpha_weights = nn.Parameter(torch.ones(node_dim) / node_dim)

        # å­˜å‚¨å˜é‡
        self.stored_alphas = None

    def forward(self, node_feat, text_feat, batch_num_nodes=None):
        """åº”ç”¨æ”¹è¿›çš„ä¸­æœŸèåˆ

        Args:
            node_feat: èŠ‚ç‚¹ç‰¹å¾ [total_nodes, node_dim]
            text_feat: æ–‡æœ¬ç‰¹å¾ [batch_size, text_dim]
            batch_num_nodes: æ¯ä¸ªå›¾çš„èŠ‚ç‚¹æ•°åˆ—è¡¨

        Returns:
            enhanced: å¢å¼ºåçš„èŠ‚ç‚¹ç‰¹å¾ [total_nodes, node_dim]
        """
        batch_size = text_feat.size(0)
        num_nodes = node_feat.size(0)

        # Transform text features
        text_transformed = self.text_transform(text_feat)  # [batch_size, node_dim]

        # Broadcast text features
        if num_nodes != batch_size:
            if batch_num_nodes is not None:
                text_expanded = []
                for i, num in enumerate(batch_num_nodes):
                    text_expanded.append(text_transformed[i].unsqueeze(0).repeat(num, 1))
                text_broadcasted = torch.cat(text_expanded, dim=0)
            else:
                text_pooled = text_transformed.mean(dim=0, keepdim=True)
                text_broadcasted = text_pooled.repeat(num_nodes, 1)
        else:
            text_broadcasted = text_transformed

        # === æ”¹è¿› 1: Gate è¾“å…¥å½’ä¸€åŒ– ===
        gate_input = torch.cat([node_feat, text_broadcasted], dim=-1)
        if self.use_layer_norm:
            gate_input = self.gate_norm(gate_input)

        # Compute gate values
        gate_logits = self.gate(gate_input)  # [*, node_dim]

        # === æ”¹è¿› 2: æ¸©åº¦ç¼©æ”¾ ===
        if self.gate_temperature != 1.0:
            gate_logits = gate_logits / self.gate_temperature

        # Apply activation
        if self.use_tanh_gate:
            # Tanh è¾“å‡º [-1, 1]ï¼Œæ˜ å°„åˆ° [0, 1]
            gate_values = (self.gate_activation(gate_logits) + 1) / 2
        else:
            gate_values = self.gate_activation(gate_logits)

        # === æ”¹è¿› 3: ä½¿ç”¨åŠ æƒå¹³å‡æå– alpha ===
        # è€Œä¸æ˜¯ç®€å•çš„å‡å€¼ï¼ˆé¿å…æ–¹å·®åç¼©ï¼‰
        self.stored_alphas = (gate_values * self.alpha_weights).sum(dim=1).detach().cpu()

        # Apply gating and residual connection
        enhanced = node_feat + gate_values * text_broadcasted
        enhanced = self.layer_norm(enhanced)
        enhanced = self.dropout(enhanced)

        return enhanced


# ============================================
# ç”¨äºæ›¿æ¢ç°æœ‰æ¨¡å‹çš„ Wrapper
# ============================================

def upgrade_fusion_module(model, use_layer_norm=True, use_tanh_gate=False, gate_temperature=1.5):
    """å°†æ¨¡å‹ä¸­çš„ MiddleFusionModule æ›¿æ¢ä¸ºæ”¹è¿›ç‰ˆæœ¬

    è¿™ä¸ªå‡½æ•°å¯ä»¥åœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å‡çº§ç°æœ‰æ¨¡å‹ã€‚
    æƒé‡ä¼šä»æ—§æ¨¡å—å¤åˆ¶åˆ°æ–°æ¨¡å—ã€‚

    Args:
        model: åŒ…å« MiddleFusionModule çš„ ALIGNN æ¨¡å‹
        use_layer_norm: æ˜¯å¦ä½¿ç”¨ LayerNormï¼ˆæ¨èï¼‰
        use_tanh_gate: æ˜¯å¦ä½¿ç”¨ Tanh æ›¿ä»£ Sigmoid
        gate_temperature: Gate æ¸©åº¦å‚æ•°ï¼ˆ>1 å¢åŠ å¤šæ ·æ€§ï¼‰

    Returns:
        upgraded_model: å‡çº§åçš„æ¨¡å‹
    """
    from models.alignn import MiddleFusionModule

    upgraded_count = 0

    for name, module in model.named_children():
        if isinstance(module, nn.ModuleDict):
            # å¤„ç† middle_fusion_modules
            for sub_name, sub_module in module.items():
                if isinstance(sub_module, MiddleFusionModule):
                    print(f"ğŸ”„ å‡çº§æ¨¡å—: {name}.{sub_name}")

                    # åˆ›å»ºæ–°æ¨¡å—
                    new_module = ImprovedMiddleFusionModule(
                        node_dim=sub_module.node_dim,
                        text_dim=sub_module.text_dim,
                        hidden_dim=sub_module.hidden_dim,
                        dropout=0.1,
                        use_layer_norm=use_layer_norm,
                        use_tanh_gate=use_tanh_gate,
                        gate_temperature=gate_temperature
                    )

                    # å¤åˆ¶æƒé‡
                    new_module.text_transform.load_state_dict(sub_module.text_transform.state_dict())
                    new_module.gate.weight.data = sub_module.gate[0].weight.data.clone()
                    new_module.gate.bias.data = sub_module.gate[0].bias.data.clone()
                    new_module.layer_norm.load_state_dict(sub_module.layer_norm.state_dict())

                    # æ›¿æ¢æ¨¡å—
                    module[sub_name] = new_module
                    upgraded_count += 1

    print(f"âœ… æˆåŠŸå‡çº§ {upgraded_count} ä¸ªèåˆæ¨¡å—")
    return model


# ============================================
# æµ‹è¯•å’Œæ¯”è¾ƒ
# ============================================

def test_fusion_improvement(checkpoint_path, root_dir):
    """æµ‹è¯•æ”¹è¿›å‰åçš„å·®å¼‚"""
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'crysmmnet-main/src'))

    from models.alignn import ALIGNN
    from extract_alpha_final import SimpleDataset, load_local_data, get_dataset_paths, collate_fn
    from torch.utils.data import DataLoader

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # åŠ è½½åŸå§‹æ¨¡å‹
    print("ğŸ“‚ åŠ è½½åŸå§‹æ¨¡å‹...")
    ckpt = torch.load(checkpoint_path, map_location=device, weights_only=False)
    model_original = ALIGNN(ckpt['config'])
    model_original.load_state_dict(ckpt['model'])
    model_original.to(device)
    model_original.eval()

    # å‡çº§æ¨¡å‹
    print("\nğŸ”„ å‡çº§æ¨¡å‹...")
    model_upgraded = ALIGNN(ckpt['config'])
    model_upgraded.load_state_dict(ckpt['model'])
    model_upgraded = upgrade_fusion_module(
        model_upgraded,
        use_layer_norm=True,
        use_tanh_gate=False,
        gate_temperature=1.5  # å¢åŠ æ¸©åº¦ä»¥æé«˜å¤šæ ·æ€§
    )
    model_upgraded.to(device)
    model_upgraded.eval()

    # åŠ è½½æ•°æ®
    print("\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
    cif_dir, csv_file = get_dataset_paths(root_dir, 'jarvis', 'hse_bandgap-2')
    raw_data = load_local_data(cif_dir, csv_file, max_samples=10)
    loader = DataLoader(SimpleDataset(raw_data, tokenizer=None), batch_size=2, collate_fn=collate_fn)

    # æµ‹è¯•
    batch = next(iter(loader))
    g, lg, text_list, _, _, _ = batch

    print("\nğŸ“ˆ æ¯”è¾ƒç»“æœ:")
    print("=" * 60)

    with torch.no_grad():
        # åŸå§‹æ¨¡å‹
        _ = model_original((g.to(device), lg.to(device), text_list))
        fusion_orig = None
        for module in model_original.modules():
            if hasattr(module, 'stored_alphas') and module.stored_alphas is not None:
                fusion_orig = module.stored_alphas.numpy()
                break

        # å‡çº§æ¨¡å‹
        _ = model_upgraded((g.to(device), lg.to(device), text_list))
        fusion_new = None
        for module in model_upgraded.modules():
            if hasattr(module, 'stored_alphas') and module.stored_alphas is not None:
                fusion_new = module.stored_alphas.numpy()
                break

    if fusion_orig is not None and fusion_new is not None:
        print(f"\nåŸå§‹æ¨¡å‹:")
        print(f"  - Alpha å‡å€¼: {fusion_orig.mean():.4f}")
        print(f"  - Alpha æ ‡å‡†å·®: {fusion_orig.std():.4f}")
        print(f"  - Alpha èŒƒå›´: [{fusion_orig.min():.4f}, {fusion_orig.max():.4f}]")

        print(f"\nå‡çº§æ¨¡å‹:")
        print(f"  - Alpha å‡å€¼: {fusion_new.mean():.4f}")
        print(f"  - Alpha æ ‡å‡†å·®: {fusion_new.std():.4f}")
        print(f"  - Alpha èŒƒå›´: [{fusion_new.min():.4f}, {fusion_new.max():.4f}]")

        print(f"\næ”¹è¿›:")
        std_improvement = (fusion_new.std() - fusion_orig.std()) / fusion_orig.std() * 100
        print(f"  - æ ‡å‡†å·®å˜åŒ–: {std_improvement:+.1f}%")

    print("\n" + "=" * 60)

if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--checkpoint', required=True)
    parser.add_argument('--root_dir', required=True)
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ”¹è¿›æ•ˆæœ')
    args = parser.parse_args()

    if args.test:
        test_fusion_improvement(args.checkpoint, args.root_dir)
    else:
        print("è¯·ä½¿ç”¨ --test å‚æ•°è¿è¡Œæµ‹è¯•")
