"""åº”ç”¨ç¼©æ”¾ä¿®å¤å¹¶ä¿å­˜æ¨¡å‹

è¿™ä¸ªè„šæœ¬ä¼šåŠ è½½æ¨¡å‹ï¼Œåº”ç”¨ç¼©æ”¾ä¿®å¤ï¼Œç„¶åä¿å­˜ã€‚

ä½¿ç”¨æ–¹æ³•:
python apply_scaling_fix.py \
    --input_checkpoint best_test_model.pt \
    --output_checkpoint best_test_model_scaled_12.0.pt \
    --scale_factor 12.0
"""

import os
import sys
import argparse
import torch

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'crysmmnet-main/src'))
from models.alignn import ALIGNN, MiddleFusionModule


class ScaledTextTransform(torch.nn.Module):
    """Wrapper that scales text_transform output"""

    def __init__(self, original_transform, scale_factor):
        super().__init__()
        self.original_transform = original_transform
        self.scale_factor = scale_factor

    def forward(self, x):
        output = self.original_transform(x)
        return output * self.scale_factor

    def load_state_dict(self, *args, **kwargs):
        return self.original_transform.load_state_dict(*args, **kwargs)

    def state_dict(self, *args, **kwargs):
        return self.original_transform.state_dict(*args, **kwargs)


def apply_scaling_fix(model, scale_factor=12.0):
    """åº”ç”¨ç¼©æ”¾ä¿®å¤åˆ°æ¨¡å‹çš„æ‰€æœ‰ MiddleFusionModule"""

    fixed_count = 0

    for name, module in model.named_modules():
        if isinstance(module, MiddleFusionModule):
            print(f"ğŸ”§ å¯¹ {name} åº”ç”¨ç¼©æ”¾ (factor={scale_factor})")

            # åŒ…è£… text_transform
            original_transform = module.text_transform
            module.text_transform = ScaledTextTransform(original_transform, scale_factor)

            fixed_count += 1

    print(f"âœ… æˆåŠŸåº”ç”¨ç¼©æ”¾åˆ° {fixed_count} ä¸ªèåˆæ¨¡å—")
    return model


def main():
    parser = argparse.ArgumentParser(description="åº”ç”¨ç¼©æ”¾ä¿®å¤å¹¶ä¿å­˜æ¨¡å‹")
    parser.add_argument('--input_checkpoint', required=True, help='è¾“å…¥æ¨¡å‹è·¯å¾„')
    parser.add_argument('--output_checkpoint', required=True, help='è¾“å‡ºæ¨¡å‹è·¯å¾„')
    parser.add_argument('--scale_factor', type=float, default=12.0, help='ç¼©æ”¾å› å­')
    args = parser.parse_args()

    print("=" * 80)
    print("ğŸ”§ åº”ç”¨ç¼©æ”¾ä¿®å¤")
    print("=" * 80)

    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“‚ åŠ è½½æ¨¡å‹: {args.input_checkpoint}")
    ckpt = torch.load(args.input_checkpoint, map_location='cpu', weights_only=False)
    config = ckpt['config']

    model = ALIGNN(config)
    model.load_state_dict(ckpt['model'])

    # åº”ç”¨ä¿®å¤
    print(f"\nğŸ”§ åº”ç”¨ç¼©æ”¾å› å­: {args.scale_factor}")
    model = apply_scaling_fix(model, scale_factor=args.scale_factor)

    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {args.output_checkpoint}")
    torch.save({
        'config': config,
        'model': model.state_dict()
    }, args.output_checkpoint)

    print("\n" + "=" * 80)
    print("âœ… å®Œæˆ")
    print("=" * 80)

    print(f"\nç°åœ¨å¯ä»¥ä½¿ç”¨ä¿®å¤åçš„æ¨¡å‹è¿›è¡Œåˆ†æï¼š")
    print(f"\n1. é‡æ–°è¿è¡Œèåˆè¯Šæ–­ï¼š")
    print(f"   python diagnose_fusion_effectiveness.py \\")
    print(f"       --checkpoint {args.output_checkpoint} \\")
    print(f"       --root_dir <your-root-dir>")

    print(f"\n2. é‡æ–°è¿è¡Œæ–‡æœ¬æµåˆ†æï¼š")
    print(f"   python 3.analyze_text_flow_v2.py \\")
    print(f"       --checkpoint {args.output_checkpoint} \\")
    print(f"       --root_dir <your-root-dir>")

    print(f"\n3. æå– Alpha å€¼å¹¶ç”Ÿæˆå›¾è¡¨ï¼š")
    print(f"   python 1.extract_alpha_final.py \\")
    print(f"       --checkpoint {args.output_checkpoint} \\")
    print(f"       --root_dir <your-root-dir> \\")
    print(f"       --dataset jarvis \\")
    print(f"       --property hse_bandgap-2 \\")
    print(f"       --n_samples 500")
    print(f"\n   python 2.create_paper_alpha_figures.py")


if __name__ == '__main__':
    main()
