"""å¿«é€Ÿæµ‹è¯•ç¼©æ”¾ä¿®å¤æ•ˆæœ

è¿™ä¸ªè„šæœ¬ä¼šåŠ¨æ€ä¿®æ”¹æ¨¡å‹çš„ text_transform è¾“å‡ºï¼Œæ— éœ€ä¿®æ”¹æºä»£ç ã€‚

ä½¿ç”¨æ–¹æ³•:
python test_scaling_fix.py \
    --checkpoint <path> \
    --root_dir <path> \
    --scale_factor 12.0

å®ƒä¼šï¼š
1. åŠ è½½æ¨¡å‹
2. åº”ç”¨ç¼©æ”¾ä¿®å¤
3. è¿è¡Œè¯Šæ–­
4. æ¯”è¾ƒä¿®å¤å‰åçš„æ•ˆæœ
"""

import os
import sys
import argparse
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'crysmmnet-main/src'))
from models.alignn import ALIGNN, MiddleFusionModule
from extract_alpha_final import SimpleDataset, load_local_data, get_dataset_paths, collate_fn


class ScaledTextTransform(torch.nn.Module):
    """Wrapper that scales text_transform output"""

    def __init__(self, original_transform, scale_factor):
        super().__init__()
        self.original_transform = original_transform
        self.scale_factor = scale_factor

    def forward(self, x):
        output = self.original_transform(x)
        return output * self.scale_factor

    def load_state_dict(self, *args, **kwargs):
        return self.original_transform.load_state_dict(*args, **kwargs)

    def state_dict(self, *args, **kwargs):
        return self.original_transform.state_dict(*args, **kwargs)


def apply_scaling_fix(model, scale_factor=12.0):
    """åº”ç”¨ç¼©æ”¾ä¿®å¤åˆ°æ¨¡å‹çš„æ‰€æœ‰ MiddleFusionModule"""

    fixed_count = 0

    for name, module in model.named_modules():
        if isinstance(module, MiddleFusionModule):
            print(f"ğŸ”§ å¯¹ {name} åº”ç”¨ç¼©æ”¾ (factor={scale_factor})")

            # åŒ…è£… text_transform
            original_transform = module.text_transform
            module.text_transform = ScaledTextTransform(original_transform, scale_factor)

            fixed_count += 1

    print(f"âœ… æˆåŠŸåº”ç”¨ç¼©æ”¾åˆ° {fixed_count} ä¸ªèåˆæ¨¡å—\n")
    return model


def run_diagnostic(model, data_loader, device):
    """è¿è¡Œç®€åŒ–çš„è¯Šæ–­"""

    # æ‰¾åˆ° fusion æ¨¡å—
    fusion_module = None
    for module in model.modules():
        if isinstance(module, MiddleFusionModule):
            fusion_module = module
            break

    if not fusion_module:
        print("âŒ æœªæ‰¾åˆ° MiddleFusionModule")
        return None

    # è·å–ä¸€ä¸ª batch
    batch = next(iter(data_loader))
    g, lg, text_list, _, _, _ = batch

    # Hook æ•è·æ•°æ®
    captured_data = {}

    def hook_fusion_input(module, input_tuple, output):
        node_feat, text_feat, batch_num_nodes = input_tuple
        captured_data['node_feat'] = node_feat.detach()
        captured_data['text_feat_in'] = text_feat.detach()

    def hook_text_transform(module, input, output):
        captured_data['text_feat_out'] = output.detach()

    def hook_gate(module, input, output):
        captured_data['gate_input'] = input[0].detach()

    # æ³¨å†Œ hooks
    h1 = fusion_module.register_forward_hook(hook_fusion_input)
    h2 = fusion_module.text_transform.register_forward_hook(hook_text_transform)
    h3 = fusion_module.gate.register_forward_hook(hook_gate)

    # è¿è¡Œ
    with torch.no_grad():
        _ = model((g.to(device), lg.to(device), text_list))

    # ç§»é™¤ hooks
    h1.remove()
    h2.remove()
    h3.remove()

    # è®¡ç®—ç»Ÿè®¡
    node_feat = captured_data['node_feat']
    text_in = captured_data['text_feat_in']
    text_out = captured_data['text_feat_out']
    gate_input = captured_data['gate_input']

    node_norm = node_feat.norm(dim=1).mean().item()
    text_in_norm = text_in.norm(dim=1).mean().item()
    text_out_norm = text_out.norm(dim=1).mean().item()

    node_part_norm = gate_input[:, :256].norm(dim=1).mean().item()
    text_part_norm = gate_input[:, 256:].norm(dim=1).mean().item()
    ratio = node_part_norm / (text_part_norm + 1e-8)

    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    batch_num_nodes = g.batch_num_nodes().tolist()
    text_expanded = []
    for i, num in enumerate(batch_num_nodes):
        if i < len(text_out):
            text_expanded.append(text_out[i].unsqueeze(0).repeat(num, 1))

    if text_expanded:
        text_broadcasted = torch.cat(text_expanded, dim=0)
        cos_sim = F.cosine_similarity(node_feat, text_broadcasted, dim=1).mean().item()
    else:
        cos_sim = 0.0

    return {
        'node_norm': node_norm,
        'text_in_norm': text_in_norm,
        'text_out_norm': text_out_norm,
        'ratio': ratio,
        'cos_sim': cos_sim
    }


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•ç¼©æ”¾ä¿®å¤æ•ˆæœ")
    parser.add_argument('--checkpoint', required=True, help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--root_dir', required=True, help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--scale_factor', type=float, default=12.0, help='ç¼©æ”¾å› å­')
    parser.add_argument('--n_samples', type=int, default=10, help='æµ‹è¯•æ ·æœ¬æ•°')
    args = parser.parse_args()

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    print("=" * 80)
    print("ğŸ§ª ç¼©æ”¾ä¿®å¤æ•ˆæœæµ‹è¯•")
    print("=" * 80)

    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“‚ åŠ è½½æ¨¡å‹: {args.checkpoint}")
    ckpt = torch.load(args.checkpoint, map_location=device, weights_only=False)
    config = ckpt['config']

    # åŠ è½½æ•°æ®
    print(f"\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ® ({args.n_samples} ä¸ªæ ·æœ¬)...")
    cif_dir, csv_file = get_dataset_paths(args.root_dir, 'jarvis', 'hse_bandgap-2')
    raw_data = load_local_data(cif_dir, csv_file, max_samples=args.n_samples)

    if not raw_data:
        print("âŒ æ— æ³•åŠ è½½æ•°æ®")
        return

    loader = DataLoader(SimpleDataset(raw_data, tokenizer=None), batch_size=2, collate_fn=collate_fn)

    # ===== æµ‹è¯•åŸå§‹æ¨¡å‹ =====
    print("\n" + "=" * 80)
    print("ğŸ“Š åŸå§‹æ¨¡å‹è¯Šæ–­")
    print("=" * 80)

    model_original = ALIGNN(config)
    model_original.load_state_dict(ckpt['model'])
    model_original.to(device)
    model_original.eval()

    results_original = run_diagnostic(model_original, loader, device)

    if results_original:
        print(f"\ntext_transform è¾“å…¥ L2:  {results_original['text_in_norm']:.4f}")
        print(f"text_transform è¾“å‡º L2:  {results_original['text_out_norm']:.4f}")
        print(f"èŠ‚ç‚¹ç‰¹å¾ L2:            {results_original['node_norm']:.4f}")
        print(f"èŠ‚ç‚¹/æ–‡æœ¬æ¯”ä¾‹:          {results_original['ratio']:.2f}:1")
        print(f"ä½™å¼¦ç›¸ä¼¼åº¦:             {results_original['cos_sim']:.4f}")

    # ===== æµ‹è¯•ä¿®å¤åæ¨¡å‹ =====
    print("\n" + "=" * 80)
    print(f"ğŸ“Š ä¿®å¤åæ¨¡å‹è¯Šæ–­ (scale_factor={args.scale_factor})")
    print("=" * 80)

    model_fixed = ALIGNN(config)
    model_fixed.load_state_dict(ckpt['model'])
    model_fixed = apply_scaling_fix(model_fixed, scale_factor=args.scale_factor)
    model_fixed.to(device)
    model_fixed.eval()

    results_fixed = run_diagnostic(model_fixed, loader, device)

    if results_fixed:
        print(f"\ntext_transform è¾“å…¥ L2:  {results_fixed['text_in_norm']:.4f}")
        print(f"text_transform è¾“å‡º L2:  {results_fixed['text_out_norm']:.4f}  â† å·²ç¼©æ”¾")
        print(f"èŠ‚ç‚¹ç‰¹å¾ L2:            {results_fixed['node_norm']:.4f}")
        print(f"èŠ‚ç‚¹/æ–‡æœ¬æ¯”ä¾‹:          {results_fixed['ratio']:.2f}:1  â† æ”¹å–„ï¼")
        print(f"ä½™å¼¦ç›¸ä¼¼åº¦:             {results_fixed['cos_sim']:.4f}  â† æ”¹å–„ï¼")

    # ===== å¯¹æ¯”æ”¹è¿› =====
    if results_original and results_fixed:
        print("\n" + "=" * 80)
        print("ğŸ“ˆ æ”¹è¿›å¯¹æ¯”")
        print("=" * 80)

        ratio_improvement = (results_original['ratio'] - results_fixed['ratio']) / results_original['ratio'] * 100
        cos_improvement = (results_fixed['cos_sim'] - results_original['cos_sim']) / abs(results_original['cos_sim'] + 1e-8) * 100
        text_norm_increase = (results_fixed['text_out_norm'] - results_original['text_out_norm']) / results_original['text_out_norm'] * 100

        print(f"\ntext_transform è¾“å‡ºèŒƒæ•°: {results_original['text_out_norm']:.4f} â†’ {results_fixed['text_out_norm']:.4f} ({text_norm_increase:+.1f}%)")
        print(f"èŠ‚ç‚¹/æ–‡æœ¬æ¯”ä¾‹:          {results_original['ratio']:.2f}:1 â†’ {results_fixed['ratio']:.2f}:1 ({ratio_improvement:+.1f}%)")
        print(f"ä½™å¼¦ç›¸ä¼¼åº¦:             {results_original['cos_sim']:.4f} â†’ {results_fixed['cos_sim']:.4f} ({cos_improvement:+.1f}%)")

        # åˆ¤æ–­
        print("\nğŸ’¡ ç»“è®º:")
        if results_fixed['ratio'] < 2.0:
            print("   âœ… ç‰¹å¾å°ºåº¦åŸºæœ¬å¹³è¡¡ (æ¯”ä¾‹ < 2:1)")
        elif results_fixed['ratio'] < 5.0:
            print("   âš ï¸  ç‰¹å¾å°ºåº¦æ”¹å–„ä½†ä»åé«˜ (æ¯”ä¾‹ 2-5:1)")
        else:
            print("   âŒ ç‰¹å¾å°ºåº¦ä»ç„¶ä¸å¹³è¡¡ (æ¯”ä¾‹ > 5:1)ï¼Œå»ºè®®å¢åŠ ç¼©æ”¾å› å­")

        if results_fixed['cos_sim'] > 0.25:
            print("   âœ… ä½™å¼¦ç›¸ä¼¼åº¦è‰¯å¥½ (> 0.25)")
        elif results_fixed['cos_sim'] > 0.15:
            print("   âš ï¸  ä½™å¼¦ç›¸ä¼¼åº¦ä¸­ç­‰ (0.15-0.25)")
        else:
            print("   âŒ ä½™å¼¦ç›¸ä¼¼åº¦ä»ç„¶åä½ (< 0.15)")

        # å»ºè®®
        print("\nğŸ“‹ å»ºè®®:")
        if results_fixed['ratio'] > 3.0:
            suggested_scale = args.scale_factor * (results_fixed['ratio'] / 1.5)
            print(f"   â€¢ å»ºè®®ä½¿ç”¨æ›´å¤§çš„ç¼©æ”¾å› å­: {suggested_scale:.1f}")
        elif results_fixed['ratio'] < 0.8:
            suggested_scale = args.scale_factor * (results_fixed['ratio'] / 1.2)
            print(f"   â€¢ å»ºè®®ä½¿ç”¨è¾ƒå°çš„ç¼©æ”¾å› å­: {suggested_scale:.1f}")
        else:
            print(f"   â€¢ å½“å‰ç¼©æ”¾å› å­ {args.scale_factor} æ•ˆæœè‰¯å¥½")

        if results_fixed['cos_sim'] > 0.2:
            print("   â€¢ å¯ä»¥ä½¿ç”¨æ­¤ç¼©æ”¾å› å­è¿›è¡Œåç»­åˆ†æå’Œå¯è§†åŒ–")
        else:
            print("   â€¢ å»ºè®®ç»“åˆ LayerNorm è¿›è¡Œé‡æ–°è®­ç»ƒä»¥è·å¾—æ›´å¥½æ•ˆæœ")

    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)

    # ä¿å­˜ä¿®å¤åçš„æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
    save_fixed = input("\næ˜¯å¦ä¿å­˜ä¿®å¤åçš„æ¨¡å‹ï¼Ÿ(y/n): ").strip().lower()
    if save_fixed == 'y':
        output_path = args.checkpoint.replace('.pt', f'_scaled_{args.scale_factor:.1f}.pt')
        torch.save({
            'config': config,
            'model': model_fixed.state_dict()
        }, output_path)
        print(f"âœ… å·²ä¿å­˜åˆ°: {output_path}")
        print(f"\nå¯ä»¥ä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œåç»­åˆ†æï¼š")
        print(f"python 1.extract_alpha_final.py --checkpoint {output_path} ...")
        print(f"python 3.analyze_text_flow_v2.py --checkpoint {output_path} ...")


if __name__ == '__main__':
    main()
