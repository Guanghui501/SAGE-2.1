# ğŸ”— é«˜çº§åæœŸèåˆæ–¹å¼ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»5ç§åæœŸèåˆæ–¹å¼ï¼Œå¸®åŠ©æ‚¨å°†å¤šæ¨¡æ€é¢„æµ‹ç²¾åº¦æå‡åˆ°æ›´é«˜æ°´å¹³ã€‚

### èåˆæ–¹å¼å¯¹æ¯”

| èåˆæ–¹å¼ | å¤æ‚åº¦ | å‚æ•°é‡ | è¡¨è¾¾èƒ½åŠ› | é€‚ç”¨åœºæ™¯ | é¢„æœŸæå‡ |
|---------|--------|--------|---------|---------|---------|
| **concat** | â­ | ä½ | åŸºç¡€ | åŸºçº¿å¯¹æ¯” | - |
| **gated** | â­â­ | ä¸­ | è¾ƒå¼º | æ¨¡æ€é‡è¦æ€§ä¸å‡è¡¡ | +2-5% |
| **bilinear** | â­â­â­ | ä¸­-é«˜ | å¼º | éœ€è¦æ•æ‰ç‰¹å¾äº¤äº’ | +3-7% |
| **adaptive** | â­â­â­â­ | é«˜ | å¾ˆå¼º | æ ·æœ¬å·®å¼‚å¤§ | +4-8% |
| **tucker** | â­â­â­â­â­ | å¯æ§ | æœ€å¼º | è¿½æ±‚æè‡´æ€§èƒ½ | +5-10% |

---

## ğŸ¯ 1. Concatèåˆï¼ˆåŸºçº¿ï¼‰

### åŸç†
ç®€å•æ‹¼æ¥å›¾ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾ï¼š`[graph_feat; text_feat]`

### ä¼˜ç‚¹
- å®ç°ç®€å•
- å‚æ•°å°‘
- è®­ç»ƒå¿«é€Ÿ

### ç¼ºç‚¹
- æ— æ³•å»ºæ¨¡è·¨æ¨¡æ€äº¤äº’
- ç‰¹å¾é‡è¦æ€§æ— æ³•è‡ªé€‚åº”

### ä½¿ç”¨ç¤ºä¾‹
```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type concat \
    --property hse_bandgap-2 \
    --output_dir ./output_baseline_concat
```

---

## ğŸšª 2. Gatedèåˆï¼ˆé—¨æ§æœºåˆ¶ï¼‰

### åŸç†
å­¦ä¹ æ¯ä¸ªæ¨¡æ€çš„é‡è¦æ€§æƒé‡ï¼š
```
gate_graph = Ïƒ(W_g Â· graph_feat)
gate_text = Ïƒ(W_t Â· text_feat)
fused = gate_graph Â· transform(graph) + gate_text Â· transform(text)
```

### ä¼˜ç‚¹
- âœ… **è‡ªé€‚åº”æƒé‡**ï¼šå¯¹ä¸åŒæ ·æœ¬å­¦ä¹ ä¸åŒçš„æ¨¡æ€æƒé‡
- âœ… **å‚æ•°é€‚ä¸­**ï¼šæ¯”concatå¤šä¸€ç‚¹ï¼Œä½†å¢ç›Šæ˜æ˜¾
- âœ… **å¯è§£é‡Šæ€§**ï¼šå¯ä»¥æŸ¥çœ‹æ¯ä¸ªæ¨¡æ€çš„è´¡çŒ®

### é€‚ç”¨åœºæ™¯
- æ¨¡æ€é‡è¦æ€§ä¸å‡è¡¡ï¼ˆå¦‚æ‚¨å‘ç°æ–‡æœ¬æ¯”å›¾é‡è¦12å€ï¼‰
- éœ€è¦è‡ªé€‚åº”å¹³è¡¡ä¸¤ä¸ªæ¨¡æ€

### ä½¿ç”¨ç¤ºä¾‹
```bash
# åŸºç¡€é…ç½®
python train_with_cross_modal_attention.py \
    --late_fusion_type gated \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --output_dir ./output_gated_fusion

# æ¨èé…ç½®ï¼ˆé€‚åˆæ‚¨çš„åœºæ™¯ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type gated \
    --late_fusion_output_dim 64 \
    --use_cross_modal True \
    --cross_modal_dropout 0.1 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 100 \
    --output_dir ./output_gated_hse
```

### å‚æ•°è¯´æ˜
- `--late_fusion_output_dim 64`ï¼šèåˆåçš„ç‰¹å¾ç»´åº¦ï¼ˆæ¨è64ï¼‰

### é¢„æœŸæ•ˆæœ
- ç›¸æ¯”concatæå‡ï¼š**2-5% MAE**
- è®­ç»ƒæ—¶é—´å¢åŠ ï¼š**<5%**

---

## ğŸ”¬ 3. Bilinearèåˆï¼ˆåŒçº¿æ€§æ± åŒ–ï¼‰

### åŸç†
æ•æ‰è·¨æ¨¡æ€çš„äºŒé˜¶ç‰¹å¾äº¤äº’ï¼ˆå¤–ç§¯ï¼‰ï¼š
```
fused = sum(UÂ·graph âŠ™ VÂ·text)  # âŠ™ è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•
```

ä½¿ç”¨ä½ç§©åˆ†è§£å‡å°‘å‚æ•°é‡ï¼ˆTuckeråˆ†è§£çš„ç‰¹ä¾‹ï¼‰

### ä¼˜ç‚¹
- âœ… **äºŒé˜¶äº¤äº’**ï¼šå»ºæ¨¡graphå’Œtextä¹‹é—´çš„ç‰¹å¾ç›¸å…³æ€§
- âœ… **è§†è§‰-è¯­è¨€é¢†åŸŸéªŒè¯**ï¼šåœ¨VQAã€å›¾åƒå­—å¹•ç­‰ä»»åŠ¡ä¸­æ•ˆæœæ˜¾è‘—
- âœ… **ä½ç§©åˆ†è§£**ï¼šå‚æ•°å¯æ§

### é€‚ç”¨åœºæ™¯
- éœ€è¦æ•æ‰è·¨æ¨¡æ€çš„å¤æ‚äº¤äº’
- å›¾ç‰¹å¾å’Œæ–‡æœ¬ç‰¹å¾å­˜åœ¨ååŒä½œç”¨

### ä½¿ç”¨ç¤ºä¾‹
```bash
# åŸºç¡€é…ç½®ï¼ˆrank=16ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type bilinear \
    --late_fusion_rank 16 \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --output_dir ./output_bilinear_r16

# é«˜ç§©é…ç½®ï¼ˆæ›´å¼ºè¡¨è¾¾èƒ½åŠ›ï¼Œrank=32ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type bilinear \
    --late_fusion_rank 32 \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 100 \
    --output_dir ./output_bilinear_r32_hse
```

### å‚æ•°è¯´æ˜
- `--late_fusion_rank`ï¼šä½ç§©åˆ†è§£çš„ç§©
  - **16**ï¼šå‚æ•°å°‘ï¼Œè®­ç»ƒå¿«ï¼ˆæ¨èèµ·å§‹å€¼ï¼‰
  - **32**ï¼šè¡¨è¾¾èƒ½åŠ›æ›´å¼ºï¼Œå‚æ•°é€‚ä¸­
  - **64**ï¼šæœ€å¼ºä½†å‚æ•°æœ€å¤š
- `--late_fusion_output_dim 64`ï¼šè¾“å‡ºç»´åº¦

### å‚æ•°é‡å¯¹æ¯”
| Rank | å‚æ•°é‡ | è¯´æ˜ |
|------|--------|------|
| 8 | ~33K | æœ€è½»é‡ |
| 16 | ~66K | **æ¨è** |
| 32 | ~132K | é«˜è¡¨è¾¾åŠ› |
| 64 | ~262K | æœ€å¼º |

### é¢„æœŸæ•ˆæœ
- ç›¸æ¯”concatæå‡ï¼š**3-7% MAE**
- è®­ç»ƒæ—¶é—´å¢åŠ ï¼š**10-15%**

---

## ğŸ¨ 4. Adaptiveèåˆï¼ˆè‡ªé€‚åº”å¤šç­–ç•¥ï¼‰

### åŸç†
ç»“åˆ3ç§èåˆç­–ç•¥ï¼Œå­¦ä¹ æ¯ä¸ªæ ·æœ¬çš„æœ€ä½³ç»„åˆï¼š
```
weight = softmax(predictor(graph, text))  # [åŠ æ³•, ä¹˜æ³•, é—¨æ§]
fused = weight[0]Â·(g+t) + weight[1]Â·(gâŠ™t) + weight[2]Â·gate(g,t)
```

### ä¼˜ç‚¹
- âœ… **å¤šç­–ç•¥ç»„åˆ**ï¼šåŠ æ³•ã€ä¹˜æ³•ã€é—¨æ§è‡ªåŠ¨é€‰æ‹©
- âœ… **æ ·æœ¬è‡ªé€‚åº”**ï¼šä¸åŒæ ·æœ¬ä½¿ç”¨ä¸åŒç­–ç•¥
- âœ… **é²æ£’æ€§å¼º**ï¼šé€‚åº”æ€§å¹¿

### é€‚ç”¨åœºæ™¯
- æ•°æ®é›†æ ·æœ¬å·®å¼‚å¤§
- ä¸ç¡®å®šå“ªç§èåˆç­–ç•¥æœ€ä¼˜
- è¿½æ±‚ç¨³å®šæ€§å’Œé²æ£’æ€§

### ä½¿ç”¨ç¤ºä¾‹
```bash
# åŸºç¡€é…ç½®
python train_with_cross_modal_attention.py \
    --late_fusion_type adaptive \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --output_dir ./output_adaptive_fusion

# æ¨èé…ç½®ï¼ˆåŠ å¼ºæ­£åˆ™åŒ–ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type adaptive \
    --late_fusion_output_dim 64 \
    --cross_modal_dropout 0.15 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 120 \
    --output_dir ./output_adaptive_hse
```

### å‚æ•°è¯´æ˜
- `--late_fusion_output_dim 64`ï¼šèåˆåç»´åº¦
- `--cross_modal_dropout 0.15`ï¼šå»ºè®®ç¨å¾®æé«˜dropouté˜²æ­¢è¿‡æ‹Ÿåˆ

### é¢„æœŸæ•ˆæœ
- ç›¸æ¯”concatæå‡ï¼š**4-8% MAE**
- è®­ç»ƒæ—¶é—´å¢åŠ ï¼š**15-20%**
- æ³›åŒ–æ€§èƒ½ä¼˜ç§€

---

## ğŸ§® 5. Tuckerèåˆï¼ˆé«˜é˜¶å¼ é‡åˆ†è§£ï¼‰

### åŸç†
ä½¿ç”¨Tuckeråˆ†è§£å»ºæ¨¡é«˜é˜¶ç‰¹å¾äº¤äº’ï¼š
```
graph_compressed = W_g Â· graph  # [batch, rank]
text_compressed = W_t Â· text    # [batch, rank]
core_tensor = graph_compressed âŠ— text_compressed  # [batch, rank, rank]
fused = W_core Â· flatten(core_tensor)
```

### ä¼˜ç‚¹
- âœ… **é«˜é˜¶äº¤äº’**ï¼šæ•æ‰æ›´å¤æ‚çš„è·¨æ¨¡æ€å…³ç³»
- âœ… **å‚æ•°å¯æ§**ï¼šé€šè¿‡rankæ§åˆ¶å‚æ•°é‡
- âœ… **ç†è®ºæ”¯æ’‘**ï¼šå¼ é‡åˆ†è§£åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­è¡¨ç°ä¼˜å¼‚

### é€‚ç”¨åœºæ™¯
- è¿½æ±‚æè‡´æ€§èƒ½
- æ•°æ®é‡å……è¶³ï¼ˆéœ€è¦æ›´å¤šæ•°æ®æ”¯æ’‘å¤æ‚æ¨¡å‹ï¼‰
- è®¡ç®—èµ„æºå……è¶³

### ä½¿ç”¨ç¤ºä¾‹
```bash
# åŸºç¡€é…ç½®ï¼ˆrank=8ï¼Œè½»é‡çº§ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 8 \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --output_dir ./output_tucker_r8

# æ¨èé…ç½®ï¼ˆrank=16ï¼Œå¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 16 \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 100 \
    --learning_rate 0.001 \
    --output_dir ./output_tucker_r16_hse

# é«˜æ€§èƒ½é…ç½®ï¼ˆrank=32ï¼Œè¿½æ±‚æè‡´ï¼‰
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 32 \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --batch_size 64 \
    --epochs 150 \
    --learning_rate 0.0005 \
    --weight_decay 0.001 \
    --output_dir ./output_tucker_r32_extreme
```

### å‚æ•°è¯´æ˜
- `--late_fusion_rank`ï¼šTuckeråˆ†è§£çš„ç§©
  - **8**ï¼šæœ€è½»é‡ï¼ˆ64å‚æ•°/è¾“å‡ºç»´åº¦ï¼‰
  - **16**ï¼šæ¨èï¼ˆ256å‚æ•°/è¾“å‡ºç»´åº¦ï¼‰
  - **32**ï¼šé«˜æ€§èƒ½ï¼ˆ1024å‚æ•°/è¾“å‡ºç»´åº¦ï¼‰

### å‚æ•°é‡å¯¹æ¯”
| Rank | Core Tensor Size | å‚æ•°é‡ä¼°è®¡ |
|------|------------------|-----------|
| 8 | 8Ã—8=64 | ~21K |
| 16 | 16Ã—16=256 | ~34K |
| 32 | 32Ã—32=1024 | ~69K |

### é¢„æœŸæ•ˆæœ
- ç›¸æ¯”concatæå‡ï¼š**5-10% MAE**
- è®­ç»ƒæ—¶é—´å¢åŠ ï¼š**20-25%**
- æœ€å¼ºè¡¨è¾¾èƒ½åŠ›

---

## ğŸ“Š å®Œæ•´è®­ç»ƒç¤ºä¾‹

### åœºæ™¯1ï¼šå¿«é€ŸéªŒè¯ï¼ˆGatedèåˆï¼‰
```bash
python train_with_cross_modal_attention.py \
    --dataset jarvis \
    --property hse_bandgap-2 \
    --root_dir ./data \
    --late_fusion_type gated \
    --late_fusion_output_dim 64 \
    --batch_size 128 \
    --epochs 100 \
    --learning_rate 0.001 \
    --use_cross_modal True \
    --output_dir ./output_gated_quick
```

### åœºæ™¯2ï¼šè¿½æ±‚æ€§èƒ½ï¼ˆTuckerèåˆ + ä¸­æœŸèåˆï¼‰
```bash
python train_with_cross_modal_attention.py \
    --dataset jarvis \
    --property hse_bandgap-2 \
    --root_dir ./data \
    --late_fusion_type tucker \
    --late_fusion_rank 16 \
    --late_fusion_output_dim 64 \
    --use_cross_modal True \
    --use_middle_fusion True \
    --middle_fusion_layers "2" \
    --middle_fusion_use_learnable_scale True \
    --middle_fusion_initial_scale 12.0 \
    --batch_size 128 \
    --epochs 120 \
    --learning_rate 0.001 \
    --weight_decay 0.0001 \
    --output_dir ./output_tucker_middle_complete
```

### åœºæ™¯3ï¼šé²æ£’æ€§ä¼˜å…ˆï¼ˆAdaptiveèåˆï¼‰
```bash
python train_with_cross_modal_attention.py \
    --dataset jarvis \
    --property hse_bandgap-2 \
    --root_dir ./data \
    --late_fusion_type adaptive \
    --late_fusion_output_dim 64 \
    --use_cross_modal True \
    --cross_modal_dropout 0.15 \
    --batch_size 128 \
    --epochs 100 \
    --learning_rate 0.001 \
    --early_stopping_patience 15 \
    --output_dir ./output_adaptive_robust
```

### åœºæ™¯4ï¼šæé™æ€§èƒ½ï¼ˆTucker + Bilinearç»„åˆå®éªŒï¼‰
```bash
# å…ˆç”¨Bilinear warm-up
python train_with_cross_modal_attention.py \
    --late_fusion_type bilinear \
    --late_fusion_rank 32 \
    --late_fusion_output_dim 64 \
    --epochs 50 \
    --output_dir ./output_warmup_bilinear

# å†ç”¨Tuckerå¾®è°ƒ
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 32 \
    --late_fusion_output_dim 64 \
    --epochs 100 \
    --learning_rate 0.0005 \
    --resume 1 \
    --output_dir ./output_finetune_tucker
```

---

## ğŸ” å‚æ•°é€‰æ‹©æŒ‡å—

### 1. `--late_fusion_output_dim`ï¼ˆèåˆè¾“å‡ºç»´åº¦ï¼‰
- **æ¨èå€¼**ï¼š64
- **å¯é€‰å€¼**ï¼š32, 64, 128
- **é€‰æ‹©ä¾æ®**ï¼š
  - 32ï¼šæœ€è½»é‡ï¼Œé€‚åˆå°æ•°æ®é›†
  - 64ï¼š**æ¨è**ï¼Œå¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡
  - 128ï¼šå¤§æ•°æ®é›†æˆ–è¿½æ±‚æè‡´æ€§èƒ½

### 2. `--late_fusion_rank`ï¼ˆä½ç§©åˆ†è§£ç§©ï¼‰
- **é€‚ç”¨äº**ï¼šbilinear, tucker
- **æ¨èå€¼**ï¼š16
- **å¯é€‰å€¼**ï¼š8, 16, 32, 64
- **é€‰æ‹©ä¾æ®**ï¼š
  - æ•°æ®é‡ < 5000ï¼šrank=8
  - æ•°æ®é‡ 5000-20000ï¼šrank=16 âœ…
  - æ•°æ®é‡ > 20000ï¼šrank=32

### 3. `--cross_modal_dropout`ï¼ˆDropoutç‡ï¼‰
- **Concat/Gated**ï¼š0.1
- **Bilinear/Tucker**ï¼š0.1-0.15
- **Adaptive**ï¼š0.15-0.2ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”å®éªŒ

### å»ºè®®çš„å¯¹æ¯”å®éªŒæµç¨‹

#### ç¬¬1æ­¥ï¼šåŸºçº¿æµ‹è¯•ï¼ˆConcatï¼‰
```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type concat \
    --output_dir ./ablation/01_baseline_concat
```

#### ç¬¬2æ­¥ï¼šé—¨æ§èåˆï¼ˆGatedï¼‰
```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type gated \
    --late_fusion_output_dim 64 \
    --output_dir ./ablation/02_gated
```

#### ç¬¬3æ­¥ï¼šåŒçº¿æ€§èåˆï¼ˆBilinearï¼‰
```bash
# Rank=16
python train_with_cross_modal_attention.py \
    --late_fusion_type bilinear \
    --late_fusion_rank 16 \
    --late_fusion_output_dim 64 \
    --output_dir ./ablation/03_bilinear_r16

# Rank=32
python train_with_cross_modal_attention.py \
    --late_fusion_type bilinear \
    --late_fusion_rank 32 \
    --late_fusion_output_dim 64 \
    --output_dir ./ablation/04_bilinear_r32
```

#### ç¬¬4æ­¥ï¼šè‡ªé€‚åº”èåˆï¼ˆAdaptiveï¼‰
```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type adaptive \
    --late_fusion_output_dim 64 \
    --cross_modal_dropout 0.15 \
    --output_dir ./ablation/05_adaptive
```

#### ç¬¬5æ­¥ï¼šTuckerèåˆï¼ˆæœ€å¼ºï¼‰
```bash
# Rank=16
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 16 \
    --late_fusion_output_dim 64 \
    --output_dir ./ablation/06_tucker_r16

# Rank=32
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 32 \
    --late_fusion_output_dim 64 \
    --output_dir ./ablation/07_tucker_r32
```

---

## ğŸ¯ æ¨èç­–ç•¥

### æ ¹æ®æ‚¨çš„åœºæ™¯ï¼ˆææ–™ç§‘å­¦ + å¸¦éš™é¢„æµ‹ï¼‰

#### ğŸ¥‡ é¦–é€‰æ–¹æ¡ˆï¼šGatedèåˆ
**åŸå› **ï¼š
- æ‚¨å·²å‘ç°æ–‡æœ¬é‡è¦æ€§æ˜¯å›¾çš„12å€
- Gatedèåˆå¯ä»¥è‡ªé€‚åº”å­¦ä¹ æ¨¡æ€æƒé‡
- å‚æ•°é€‚ä¸­ï¼Œè®­ç»ƒæ•ˆç‡é«˜

```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type gated \
    --late_fusion_output_dim 64 \
    --use_middle_fusion True \
    --middle_fusion_use_learnable_scale True \
    --middle_fusion_initial_scale 12.0 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 100 \
    --output_dir ./output_gated_recommended
```

#### ğŸ¥ˆ æ¬¡é€‰æ–¹æ¡ˆï¼šTuckerèåˆï¼ˆRank=16ï¼‰
**åŸå› **ï¼š
- è¿½æ±‚æ›´é«˜ç²¾åº¦
- é«˜é˜¶äº¤äº’å»ºæ¨¡
- Rank=16å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡

```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --late_fusion_rank 16 \
    --late_fusion_output_dim 64 \
    --use_middle_fusion True \
    --middle_fusion_use_learnable_scale True \
    --middle_fusion_initial_scale 12.0 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 120 \
    --output_dir ./output_tucker_recommended
```

#### ğŸ¥‰ å¤‡é€‰æ–¹æ¡ˆï¼šAdaptiveèåˆ
**åŸå› **ï¼š
- æ ·æœ¬å·®å¼‚å¤§æ—¶è¡¨ç°ä¼˜å¼‚
- é²æ£’æ€§å¼º
- é€‚åˆä¸ç¡®å®šæœ€ä¼˜ç­–ç•¥çš„åœºæ™¯

```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type adaptive \
    --late_fusion_output_dim 64 \
    --cross_modal_dropout 0.15 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 100 \
    --output_dir ./output_adaptive_recommended
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. è®­ç»ƒç¨³å®šæ€§
- **Bilinear/Tucker**ï¼šåˆå§‹å­¦ä¹ ç‡å¯èƒ½éœ€è¦é™ä½ï¼ˆ0.0005-0.001ï¼‰
- **Adaptive**ï¼šå»ºè®®æé«˜dropoutï¼ˆ0.15-0.2ï¼‰
- **æ‰€æœ‰æ–¹æ³•**ï¼šå»ºè®®ä½¿ç”¨early stopping

### 2. å†…å­˜å ç”¨
- **Concat**ï¼šæœ€ä½
- **Gated**ï¼šç¨é«˜ï¼ˆ+10-15%ï¼‰
- **Bilinear/Tucker**ï¼šä¸­ç­‰ï¼ˆ+20-30%ï¼Œå–å†³äºrankï¼‰
- **Adaptive**ï¼šè¾ƒé«˜ï¼ˆ+30-40%ï¼‰

### 3. è®­ç»ƒæ—¶é—´
- **Concat**ï¼šåŸºçº¿
- **Gated**ï¼š+5%
- **Bilinear**ï¼š+10-15%
- **Adaptive**ï¼š+15-20%
- **Tucker**ï¼š+20-25%

### 4. Resumeè®­ç»ƒ
æ‰€æœ‰èåˆæ–¹å¼éƒ½æ”¯æŒresumeï¼š
```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type tucker \
    --resume 1 \
    --output_dir ./output_previous_experiment
```

---

## ğŸ“š æŠ€æœ¯ç»†èŠ‚

### Gatedèåˆæ•°å­¦å…¬å¼
```
g_weight = Ïƒ(MLP_g(graph_feat))
t_weight = Ïƒ(MLP_t(text_feat))
normalize: g_w, t_w = softmax([g_weight, t_weight])
fused = g_w Â· Linear_g(graph) + t_w Â· Linear_t(text)
```

### Bilinearèåˆæ•°å­¦å…¬å¼
```
# ä½ç§©åˆ†è§£
U = Linear(graph, rank Ã— output_dim)  # [batch, rank, output_dim]
V = Linear(text, rank Ã— output_dim)   # [batch, rank, output_dim]
fused = sum(U âŠ™ V, dim=rank)          # [batch, output_dim]
```

### Adaptiveèåˆæ•°å­¦å…¬å¼
```
fusion_weights = softmax(MLP([graph; text]))  # [batch, 3]
fusion_add = graph + text
fusion_mul = graph âŠ™ text
fusion_gate = Ïƒ(W) Â· graph + (1-Ïƒ(W)) Â· text
fused = w[0]Â·f_add + w[1]Â·f_mul + w[2]Â·f_gate
```

### Tuckerèåˆæ•°å­¦å…¬å¼
```
g_compressed = W_g Â· graph  # [batch, rank]
t_compressed = W_t Â· text   # [batch, rank]
core = g_compressed âŠ— t_compressed  # [batch, rank, rank]
fused = W_core Â· flatten(core)      # [batch, output_dim]
```

---

## ğŸ”§ è°ƒè¯•æŠ€å·§

### 1. æ£€æŸ¥èåˆé…ç½®
è®­ç»ƒå¼€å§‹æ—¶ä¼šæ‰“å°èåˆé…ç½®ï¼š
```
================================================================================
ğŸ”— åæœŸèåˆé…ç½®
================================================================================
èåˆç±»å‹: tucker
å‚æ•°: Tuckeråˆ†è§£èåˆï¼ŒRank=16, è¾“å‡ºç»´åº¦ 64
================================================================================
```

### 2. ç›‘æ§è®­ç»ƒæŒ‡æ ‡
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f nohup.out

# æ£€æŸ¥æœ€ä½³æ¨¡å‹
python check_checkpoints.py --checkpoint_dir ./output_tucker_r16_hse/hse_bandgap-2
```

### 3. å¯¹æ¯”å®éªŒç»“æœ
```bash
# æ”¶é›†æ‰€æœ‰å®éªŒçš„val_mae
grep "Best Validation MAE" ./ablation/*/hse_bandgap-2/train.log
```

---

## ğŸ“– å‚è€ƒæ–‡çŒ®

1. **Gated Fusion**: "Gated Multimodal Units for Information Fusion" (arXiv:1702.01992)
2. **Bilinear Pooling**: "Multimodal Compact Bilinear Pooling" (EMNLP 2016)
3. **Tucker Decomposition**: "MUTAN: Multimodal Tucker Fusion" (ICCV 2017)
4. **Adaptive Fusion**: "Efficient Low-rank Multimodal Fusion" (NeurIPS 2018)

---

## ğŸš€ å¼€å§‹ä½¿ç”¨

**æ¨èç¬¬ä¸€æ­¥**ï¼šä»Gatedèåˆå¼€å§‹
```bash
python train_with_cross_modal_attention.py \
    --late_fusion_type gated \
    --late_fusion_output_dim 64 \
    --property hse_bandgap-2 \
    --batch_size 128 \
    --epochs 100 \
    --output_dir ./output_gated_first_try
```

ç¥æ‚¨å†²åˆºæ›´é«˜ç²¾åº¦ï¼ğŸ¯
